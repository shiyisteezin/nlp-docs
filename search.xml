<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Auto Differentiation</title>
    <url>/nlp-docs/2024/07/14/audo-diff/</url>
    <content><![CDATA[<h3 id="Intro-to-Automatic-Differentiation"><a href="#Intro-to-Automatic-Differentiation" class="headerlink" title="Intro to Automatic Differentiation"></a>Intro to Automatic Differentiation</h3><p>In this blog, we will go through the foundations behind Automatic Differentiation.</p>
<div style="margin-left:1px; margin-top: 30px">
  <iframe id="iframe-yt-video" width="100%" height="520" src="https://www.youtube.com/embed/56WUlMEeAuA?enablejsapi=1&autoplay=1" frameborder="0"></iframe>
</div>

<h4 id="The-Breakdown-of-The-Video-Into-Parts"><a href="#The-Breakdown-of-The-Video-Into-Parts" class="headerlink" title="The Breakdown of The Video Into Parts"></a>The Breakdown of The Video Into Parts</h4><script src="https://www.youtube.com/iframe_api"></script>

<script>
    var player;

    // This function is called by the YouTube IFrame API when it's ready
    function onYouTubeIframeAPIReady() {
        player = new YT.Player('iframe-yt-video', {
            events: {
                'onReady': onPlayerReady
            }
        });
    }

    // This function is called when the player is ready
    function onPlayerReady(event) {
        console.log("YouTube Player is ready");

        // Attach event listeners to the buttons
        document.querySelectorAll('.btn-timestamp').forEach(function(button) {
            button.addEventListener('click', function() {
                var seconds = parseInt(this.getAttribute('data-seconds'), 10);
                seekTo(seconds);
            });
        });
    }

    // Function to seek to the specified time in the video
    function seekTo(seconds) {
        if (player && typeof player.seekTo === 'function') {
            player.pauseVideo(); // Pause the video first
            player.seekTo(seconds, true); // Seek to the specified time
            setTimeout(function() {
                player.playVideo(); // Attempt to play after a short delay
            }, 500); // Adjust delay as needed
            console.log("Seeking to:", seconds, "seconds");
        } else {
            console.log("Player is not ready yet");
        }
    }
</script>

<div class="video-timestamps">
  <button class="btn-timestamp" data-seconds="0">Introduction</button>
  <button class="btn-timestamp" data-seconds="53">Topic 1 - Diff in ML</button>
  <button class="btn-timestamp" data-seconds="316">Topic 2 - Numerical Diff</button>
  <button class="btn-timestamp" data-seconds="697">Topic 2 - Gradient Checking</button>
  <button class="btn-timestamp" data-seconds="848">Topic 3 - Symbolic Diff</button>
  <button class="btn-timestamp" data-seconds="1108">Topic 4 - Computational Graphs</button>
  <button class="btn-timestamp" data-seconds="1367">Topic 5 - Forward Automatic Diff</button>
  <button class="btn-timestamp" data-seconds="1992">Topic 6 - Reverse Auto Diff</button>
  <button class="btn-timestamp" data-seconds="2532">Topic 6 - Reverse AD Algorithm</button>
  <button class="btn-timestamp" data-seconds="3299">Topic 7 - RAD vs Backprop</button>

</div>


<h4 id="Important-Transcripts-of-the-Video"><a href="#Important-Transcripts-of-the-Video" class="headerlink" title="Important Transcripts of the Video"></a>Important Transcripts of the Video</h4>]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title>Compositionality</title>
    <url>/nlp-docs/2024/09/17/compositionality/</url>
    <content><![CDATA[<h3 id="Dealing-with-Compositionality"><a href="#Dealing-with-Compositionality" class="headerlink" title="Dealing with Compositionality"></a>Dealing with Compositionality</h3><p>This blog will introduce the research done in syntax that addressed compositionality. In one of the connectionist natural language processing papers I have read about, it touches on government binding theory proposed by Chomsky, and the paper tried to model the motion from d-structure to s-structure in GB theory through the non-overlap constraint and chain map combined with NNs.</p>
<p>And the demonstration of the non-overlap map is below</p>
<p><img src="/nlp-docs/images/non-overlap.jpg"></p>
<h4 id="Non-Overlap-Constraint-Explained"><a href="#Non-Overlap-Constraint-Explained" class="headerlink" title="Non-Overlap Constraint Explained"></a>Non-Overlap Constraint Explained</h4><p>The non-overlap constraint is a rule in cognitive models or neural networks that prevents overlapping activations of units in a chain map. This ensures that no two units representing the same syntactic marker can be active simultaneously, which helps maintain clear and distinct representations.</p>
<h4 id="Diagram-Breakdown"><a href="#Diagram-Breakdown" class="headerlink" title="Diagram Breakdown"></a>Diagram Breakdown</h4><h5 id="Components"><a href="#Components" class="headerlink" title="Components:"></a>Components:</h5><h6 id="Chain-Map-Green-Text"><a href="#Chain-Map-Green-Text" class="headerlink" title="Chain Map (Green Text):"></a>Chain Map (Green Text):</h6><ul>
<li>Represents the initial activation of units.</li>
<li>Units in this map correspond to elements or tokens that can be active.</li>
</ul>
<h6 id="Non-Overlap-Map-Red-Text"><a href="#Non-Overlap-Map-Red-Text" class="headerlink" title="Non-Overlap Map (Red Text):"></a>Non-Overlap Map (Red Text):</h6><ul>
<li>Corresponds to the chain map and enforces non-overlapping activations.</li>
<li>Units in this map prevent other units in the same diagonal from activating.</li>
</ul>
<h6 id="Diagonal-Non-Lateral-Inhibitory-Links-Black-Bold-Arrows"><a href="#Diagonal-Non-Lateral-Inhibitory-Links-Black-Bold-Arrows" class="headerlink" title="Diagonal, Non-Lateral Inhibitory Links (Black Bold Arrows):"></a>Diagonal, Non-Lateral Inhibitory Links (Black Bold Arrows):</h6><ul>
<li>These links prevent other units in the corresponding diagonal of the chain map from activating, thereby enforcing the non-overlap constraint.</li>
</ul>
<h6 id="Activation-of-Corresponding-Unit-In-The-Non-Overlap-Map-Red-Arrow"><a href="#Activation-of-Corresponding-Unit-In-The-Non-Overlap-Map-Red-Arrow" class="headerlink" title="Activation of Corresponding Unit In The Non-Overlap Map (Red Arrow)"></a>Activation of Corresponding Unit In The Non-Overlap Map (Red Arrow)</h6><ul>
<li>The red arrow or the lateral link indicates an activation process from the chain map where there is a unit activated. Correspondingly, there is a unit in direct parallel in the non-overlap map being activated.</li>
</ul>
<h6 id="Process"><a href="#Process" class="headerlink" title="Process:"></a>Process:</h6><ol>
<li>When a unit in the chain map is activated, it activates its corresponding unit in the non-overlap map.</li>
<li>The active unit in the non-overlap map then inhibits all other units in the same diagonal in the chain map.</li>
<li>This ensures no two units in the chain map, which represent the same syntactic marker, can be active simultaneously.</li>
</ol>
<h4 id="Code-Example-with-Explanation"><a href="#Code-Example-with-Explanation" class="headerlink" title="Code Example with Explanation"></a>Code Example with Explanation</h4><p>Let’s look at a pseudo implementation that matches the diagram:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Unit</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, identifier</span>):</span><br><span class="line">        <span class="variable language_">self</span>.identifier = identifier</span><br><span class="line">        <span class="variable language_">self</span>.active = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Unit(<span class="subst">&#123;self.identifier&#125;</span>, active=<span class="subst">&#123;self.active&#125;</span>)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Map</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line">        <span class="variable language_">self</span>.name = name</span><br><span class="line">        <span class="variable language_">self</span>.units = [[Unit(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span><span class="subst">&#123;<span class="built_in">chr</span>(<span class="number">65</span>+i)&#125;</span><span class="subst">&#123;j+<span class="number">1</span>&#125;</span>&quot;</span>) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]</span><br><span class="line">                                                       <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">activate_unit</span>(<span class="params">self, row, col</span>):</span><br><span class="line">        <span class="variable language_">self</span>.units[row][col].active = <span class="literal">True</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Activating <span class="subst">&#123;self.units[row][col]&#125;</span> in <span class="subst">&#123;self.name&#125;</span> map.&quot;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.enforce_non_overlap(row, col)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">enforce_non_overlap</span>(<span class="params">self, row, col</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">            <span class="keyword">if</span> i != row:</span><br><span class="line">                <span class="variable language_">self</span>.units[i][col].active = <span class="literal">False</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Deactivating <span class="subst">&#123;self.units[i][col]&#125;</span> in <span class="subst">&#123;self.name&#125;</span></span></span><br><span class="line"><span class="string">                map due tonon-overlap constraint.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize Chain Map and Non-Overlap Map</span></span><br><span class="line">chain_map = Map(<span class="string">&quot;ChainMap&quot;</span>)</span><br><span class="line">non_overlap_map = Map(<span class="string">&quot;NonOverlapMap&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Activate unit in Chain Map</span></span><br><span class="line">chain_map.activate_unit(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Corresponding unit in Non-Overlap Map becomes active</span></span><br><span class="line">non_overlap_map.activate_unit(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output the state of maps</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Chain Map State:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> chain_map.units:</span><br><span class="line">    <span class="built_in">print</span>(row)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nNon-Overlap Map State:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> non_overlap_map.units:</span><br><span class="line">    <span class="built_in">print</span>(row)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><h6 id="Chain-Map-Activation"><a href="#Chain-Map-Activation" class="headerlink" title="Chain Map Activation:"></a>Chain Map Activation:</h6><ul>
<li>Activating a unit in the chain map triggers the corresponding unit in the non-overlap map.</li>
<li>Example: Activating <code>ChainMapA1</code> will activate <code>NonOverlapMapA1</code>.</li>
</ul>
<h6 id="Non-Overlap-Map-Enforces-Constraint"><a href="#Non-Overlap-Map-Enforces-Constraint" class="headerlink" title="Non-Overlap Map Enforces Constraint:"></a>Non-Overlap Map Enforces Constraint:</h6><ul>
<li>The activated unit in the non-overlap map inhibits other units in the same diagonal in the chain map.</li>
<li>This ensures that other units in the corresponding diagonal of the chain map remain inactive, preserving the non-overlap constraint.</li>
</ul>
<h4 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h4><p>By combining the visual diagram with the detailed code example, we’ve illustrated how the non-overlap constraint is implemented and enforced in a cognitive or neural model. The non-overlap map plays a crucial role in ensuring that units representing the same syntactic marker do not overlap in their activation, maintaining a clear and distinct representation of information.</p>
]]></content>
      <categories>
        <category>Linguistics</category>
      </categories>
  </entry>
  <entry>
    <title>Intro to Determinism</title>
    <url>/nlp-docs/2024/09/02/determinism/</url>
    <content><![CDATA[<h3 id="Introduction-to-Determinism-in-Philosophy-and-Mathematics"><a href="#Introduction-to-Determinism-in-Philosophy-and-Mathematics" class="headerlink" title="Introduction to Determinism in Philosophy and Mathematics"></a><strong>Introduction to Determinism in Philosophy and Mathematics</strong></h3><p><strong>Determinism</strong> is the philosophical idea that every event or state of affairs, including human decisions, is the consequence of preceding events according to fixed laws of nature. In its purest form, determinism implies that if we had perfect knowledge of the current state of the universe, we could predict all future events with certainty.</p>
<p>In contrast, <strong>non-determinism</strong> implies the possibility of multiple potential outcomes for any given situation, introducing elements of uncertainty, chance, or randomness.</p>
<p>In <strong>mathematics</strong> and <strong>computer science</strong>, determinism refers to systems or processes where outcomes are strictly determined by initial states and inputs, leading to predictable results. Non-determinism, on the other hand, allows for multiple potential outcomes given the same initial state and inputs, introducing randomness or unpredictability.</p>
<hr>
<h3 id="Philosophical-Aspects-of-Determinism"><a href="#Philosophical-Aspects-of-Determinism" class="headerlink" title="Philosophical Aspects of Determinism"></a><strong>Philosophical Aspects of Determinism</strong></h3><p>From a <strong>philosophical</strong> perspective, determinism is often discussed in relation to:</p>
<ol>
<li><p><strong>Causality</strong>: Every effect has a specific cause, and the future is just a sequence of causes and effects that can be predicted.</p>
</li>
<li><p><strong>Free Will</strong>: One of the central debates is whether free will can exist in a deterministic universe. If everything is predetermined by prior states and natural laws, how do individuals exercise free choice?</p>
</li>
<li><p><strong>Compatibilism vs. Incompatibilism</strong>:</p>
<ul>
<li><strong>Compatibilists</strong> argue that free will and determinism are not mutually exclusive. People can still be held accountable for their actions even if those actions are predetermined by prior causes.</li>
<li><strong>Incompatibilists</strong> argue that true free will cannot exist in a deterministic framework.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="Mathematical-Aspects-of-Determinism"><a href="#Mathematical-Aspects-of-Determinism" class="headerlink" title="Mathematical Aspects of Determinism"></a><strong>Mathematical Aspects of Determinism</strong></h3><p>In <strong>mathematics</strong>, determinism is often studied through computational models and probabilistic systems that describe how inputs relate to outputs in predictable or unpredictable ways.</p>
<h4 id="1-Information-Theory-Entropy"><a href="#1-Information-Theory-Entropy" class="headerlink" title="1. Information Theory: Entropy"></a><strong>1. Information Theory: Entropy</strong></h4><ul>
<li><strong>Entropy</strong> is a measure of uncertainty or unpredictability in a system. In a <strong>deterministic</strong> system, there is little or no entropy because the outcome is always predictable.<ul>
<li><strong>Example</strong>: If you flip a coin that always lands on heads, the entropy is zero because there’s no randomness.</li>
<li><strong>Code Example (Python)</strong>:</li>
</ul>
</li>
</ul>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">entropy</span>(<span class="params">probabilities</span>):</span><br><span class="line">    <span class="keyword">return</span> -<span class="built_in">sum</span>(p * math.log2(p) <span class="keyword">for</span> p <span class="keyword">in</span> probabilities <span class="keyword">if</span> p &gt; <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example with a biased coin (always heads)</span></span><br><span class="line">probabilities = [<span class="number">1.0</span>]  <span class="comment"># deterministic, no uncertainty</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Entropy: <span class="subst">&#123;entropy(probabilities)&#125;</span>&#x27;</span>)  <span class="comment"># Output: 0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2-Markov-Chains"><a href="#2-Markov-Chains" class="headerlink" title="2. Markov Chains"></a><strong>2. Markov Chains</strong></h4><ul>
<li><strong>Markov Chains</strong> are used to model systems where the future state depends only on the current state. A Markov process can be deterministic (if there is always one future state) or stochastic (if there are multiple possible future states with different probabilities).<ul>
<li><strong>Example</strong>: A Markov chain can represent a simplified weather model where the weather today (sunny or rainy) depends only on the weather yesterday.</li>
<li><strong>Code Example (Python)</strong>:</li>
</ul>
</li>
</ul>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">markov_chain</span>(<span class="params">current_state, transitions</span>):</span><br><span class="line">    <span class="keyword">return</span> random.choices(<span class="built_in">list</span>(transitions[current_state].keys()), <span class="built_in">list</span>(transitions[current_state].values()))[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">transitions = &#123;</span><br><span class="line">    <span class="string">&#x27;sunny&#x27;</span>: &#123;<span class="string">&#x27;sunny&#x27;</span>: <span class="number">0.8</span>, <span class="string">&#x27;rainy&#x27;</span>: <span class="number">0.2</span>&#125;,</span><br><span class="line">    <span class="string">&#x27;rainy&#x27;</span>: &#123;<span class="string">&#x27;sunny&#x27;</span>: <span class="number">0.3</span>, <span class="string">&#x27;rainy&#x27;</span>: <span class="number">0.7</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Starting from &#x27;sunny&#x27;</span></span><br><span class="line">current_state = <span class="string">&#x27;sunny&#x27;</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    current_state = markov_chain(current_state, transitions)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Next state: <span class="subst">&#123;current_state&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>This example shows a <strong>stochastic</strong> process. The current state affects future states, but it’s non-deterministic due to the probabilistic transitions.</li>
</ul>
<h4 id="3-Finite-State-Machines-FSMs"><a href="#3-Finite-State-Machines-FSMs" class="headerlink" title="3. Finite State Machines (FSMs)"></a><strong>3. Finite State Machines (FSMs)</strong></h4><ul>
<li><strong>Finite State Machines</strong> are mathematical models of computation. In linguistics, they are used to model grammar and syntax.<ul>
<li><strong>Deterministic Finite Automata (DFA)</strong>: A DFA is a machine where for each state and input, there is a unique next state. It processes strings in a predictable manner.</li>
<li><strong>Non-Deterministic Finite Automata (NFA)</strong>: An NFA allows multiple possible states for a given input, introducing elements of non-determinism.</li>
</ul>
</li>
</ul>
<h4 id="Deterministic-Finite-Automata-DFA-Example"><a href="#Deterministic-Finite-Automata-DFA-Example" class="headerlink" title="Deterministic Finite Automata (DFA) Example"></a><strong>Deterministic Finite Automata (DFA) Example</strong></h4><p>A DFA processes input strings deterministically, meaning each state has exactly one possible transition for a given input.</p>
<ul>
<li><strong>Example</strong>: Recognizing binary strings that end in “01”.</li>
<li><strong>Code Example (Python)</strong>:</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DFA</span>:</span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, transition_table, start_state, accept_states</span>):</span><br><span class="line">       <span class="variable language_">self</span>.transition_table = transition_table</span><br><span class="line">       <span class="variable language_">self</span>.state = start_state</span><br><span class="line">       <span class="variable language_">self</span>.accept_states = accept_states</span><br><span class="line"></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self, input_string</span>):</span><br><span class="line">       <span class="keyword">for</span> symbol <span class="keyword">in</span> input_string:</span><br><span class="line">           <span class="variable language_">self</span>.state = <span class="variable language_">self</span>.transition_table[<span class="variable language_">self</span>.state][symbol]</span><br><span class="line">       <span class="keyword">return</span> <span class="variable language_">self</span>.state <span class="keyword">in</span> <span class="variable language_">self</span>.accept_states</span><br><span class="line"></span><br><span class="line"><span class="comment"># DFA that recognizes strings ending in &#x27;01&#x27;</span></span><br><span class="line">transition_table = &#123;</span><br><span class="line">   <span class="number">0</span>: &#123;<span class="string">&#x27;0&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;1&#x27;</span>: <span class="number">0</span>&#125;,</span><br><span class="line">   <span class="number">1</span>: &#123;<span class="string">&#x27;0&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;1&#x27;</span>: <span class="number">2</span>&#125;,</span><br><span class="line">   <span class="number">2</span>: &#123;<span class="string">&#x27;0&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;1&#x27;</span>: <span class="number">0</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line">dfa = DFA(transition_table, <span class="number">0</span>, &#123;<span class="number">2</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(dfa.process(<span class="string">&#x27;10101&#x27;</span>))  <span class="comment"># True, as it ends in &#x27;01&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(dfa.process(<span class="string">&#x27;1001&#x27;</span>))   <span class="comment"># False</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="Non-Deterministic-Finite-Automata-NFA-Example"><a href="#Non-Deterministic-Finite-Automata-NFA-Example" class="headerlink" title="Non-Deterministic Finite Automata (NFA) Example"></a><strong>Non-Deterministic Finite Automata (NFA) Example</strong></h4><p>In an NFA, a machine can move to multiple states simultaneously, and if any state reaches an accepting state, the input is accepted.</p>
<ul>
<li><strong>Example</strong>: Recognizing binary strings that contain “01” as a substring.</li>
<li><strong>Code Example (Python)</strong>:</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NFA</span>:</span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, transition_table, start_states, accept_states</span>):</span><br><span class="line">       <span class="variable language_">self</span>.transition_table = transition_table</span><br><span class="line">       <span class="variable language_">self</span>.start_states = start_states</span><br><span class="line">       <span class="variable language_">self</span>.accept_states = accept_states</span><br><span class="line"></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self, input_string</span>):</span><br><span class="line">       current_states = <span class="variable language_">self</span>.start_states</span><br><span class="line">       <span class="keyword">for</span> symbol <span class="keyword">in</span> input_string:</span><br><span class="line">           next_states = <span class="built_in">set</span>()</span><br><span class="line">           <span class="keyword">for</span> state <span class="keyword">in</span> current_states:</span><br><span class="line">               <span class="keyword">if</span> symbol <span class="keyword">in</span> <span class="variable language_">self</span>.transition_table[state]:</span><br><span class="line">                   next_states.update(<span class="variable language_">self</span>.transition_table[state][symbol])</span><br><span class="line">           current_states = next_states</span><br><span class="line">       <span class="keyword">return</span> <span class="built_in">bool</span>(current_states &amp; <span class="variable language_">self</span>.accept_states)</span><br><span class="line"></span><br><span class="line"><span class="comment"># NFA recognizing strings containing &#x27;01&#x27;</span></span><br><span class="line">transition_table = &#123;</span><br><span class="line">   <span class="number">0</span>: &#123;<span class="string">&#x27;0&#x27;</span>: &#123;<span class="number">0</span>, <span class="number">1</span>&#125;, <span class="string">&#x27;1&#x27;</span>: &#123;<span class="number">0</span>&#125;&#125;,</span><br><span class="line">   <span class="number">1</span>: &#123;<span class="string">&#x27;1&#x27;</span>: &#123;<span class="number">2</span>&#125;&#125;,</span><br><span class="line">   <span class="number">2</span>: &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">nfa = NFA(transition_table, &#123;<span class="number">0</span>&#125;, &#123;<span class="number">2</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(nfa.process(<span class="string">&#x27;10101&#x27;</span>))  <span class="comment"># True, as &#x27;01&#x27; is a substring</span></span><br><span class="line"><span class="built_in">print</span>(nfa.process(<span class="string">&#x27;1111&#x27;</span>))   <span class="comment"># False</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="DFA-vs-NFA-in-Handling-Different-Tasks"><a href="#DFA-vs-NFA-in-Handling-Different-Tasks" class="headerlink" title="DFA vs NFA in Handling Different Tasks"></a><strong>DFA vs NFA in Handling Different Tasks</strong></h4><ul>
<li><strong>DFAs</strong> are faster and easier to implement in practice because of their deterministic nature. They are predictable, and given an input string, there’s only one possible state at any time.</li>
<li><strong>NFAs</strong> offer more flexibility and simplicity in design. However, they require more complex computation to handle non-determinism, as multiple states may need to be tracked simultaneously.</li>
</ul>
<p>In computational theory, <strong>DFAs</strong> and <strong>NFAs</strong> are equivalent in power, meaning any language that can be recognized by an NFA can also be recognized by a DFA (though converting an NFA to a DFA can lead to exponential growth in the number of states).</p>
<hr>
<h3 id="Conclusion-Blending-Determinism-and-Non-Determinism"><a href="#Conclusion-Blending-Determinism-and-Non-Determinism" class="headerlink" title="Conclusion: Blending Determinism and Non-Determinism"></a><strong>Conclusion: Blending Determinism and Non-Determinism</strong></h3><p>Determinism and non-determinism are foundational concepts in both philosophical and mathematical domains. While deterministic systems allow predictability and order, non-determinism introduces flexibility and accounts for uncertainty, which is critical for modeling real-world processes. Whether in the context of linguistic models, automata theory, or information systems, blending deterministic and non-deterministic elements enables the creation of robust, flexible models for solving complex problems.</p>
]]></content>
      <categories>
        <category>Math</category>
      </categories>
  </entry>
  <entry>
    <title>Naturalizing Intentions</title>
    <url>/nlp-docs/2024/09/02/intentionality/</url>
    <content><![CDATA[<h3 id="The-Hard-Problem-in-Naturalizing-Intentionality"><a href="#The-Hard-Problem-in-Naturalizing-Intentionality" class="headerlink" title="The Hard Problem in Naturalizing Intentionality"></a><strong>The Hard Problem in Naturalizing Intentionality</strong></h3><p>The <strong>Hard Problem of Intentionality</strong> mirrors the broader <strong>Hard Problem of Consciousness</strong>, focusing on a specific aspect of mental life: <strong>intentionality</strong>—the mind’s ability to represent, think about, or be “about” things. Both problems grapple with the difficulty of explaining <em>subjective mental phenomena</em> in purely naturalistic or physical terms.</p>
<p>Let’s break this down into key concepts and challenges in a comprehensive way:</p>
<h3 id="1-What-is-Intentionality"><a href="#1-What-is-Intentionality" class="headerlink" title="1. What is Intentionality?"></a>1. <strong>What is Intentionality?</strong></h3><p><strong>Intentionality</strong> is the capacity of the mind to be directed toward objects, states, or events. When we think, perceive, believe, or desire, our mental states are always <em>about</em> something:</p>
<ul>
<li>Thinking about a tree.</li>
<li>Perceiving the sound of a car horn.</li>
<li>Believing that it will rain tomorrow.</li>
</ul>
<p>This “aboutness”—the idea that our thoughts are directed at or represent things—is what makes intentionality a unique feature of the mind. The mind doesn’t just generate random activity; it <em>represents</em> things in the world.</p>
<h3 id="2-The-Naturalization-of-Intentionality"><a href="#2-The-Naturalization-of-Intentionality" class="headerlink" title="2. The Naturalization of Intentionality"></a>2. <strong>The Naturalization of Intentionality</strong></h3><p>The goal of <strong>naturalizing intentionality</strong> is to explain this mental “aboutness” in terms of <strong>physical processes</strong>, such as brain activity, evolutionary biology, or cognitive systems. Naturalism seeks to show how the mind’s ability to represent the world can be explained as part of the natural world, without invoking anything supernatural or mysterious.</p>
<p>Many philosophers and cognitive scientists believe that intentionality can be reduced to <strong>causal relationships</strong>, <strong>information processing</strong>, or <strong>evolutionary functions</strong>. For example:</p>
<ul>
<li><strong>Causal Theories</strong> suggest that our mental representations are caused by the things they represent. You have a mental image of a tree because the tree caused certain sensory processes (light entering the eyes, neurons firing, etc.).</li>
<li><strong>Teleosemantics</strong> explains intentionality in terms of <strong>biological functions</strong>: a mental state represents something because it evolved to fulfill a particular function, such as guiding behavior in response to environmental stimuli.</li>
<li><strong>Information-Theoretic Approaches</strong> view mental states as <strong>information processors</strong>, analogous to computers that process inputs and outputs, where the inputs are representations of the external world.</li>
</ul>
<h3 id="3-The-Subjective-Nature-of-Intentionality-The-Hard-Problem"><a href="#3-The-Subjective-Nature-of-Intentionality-The-Hard-Problem" class="headerlink" title="3. The Subjective Nature of Intentionality: The Hard Problem"></a>3. <strong>The Subjective Nature of Intentionality: The Hard Problem</strong></h3><p>Despite these approaches, many philosophers argue that these <strong>naturalistic explanations leave out something essential</strong>—the <strong>subjective aspect</strong> of intentionality. This is known as the <strong>Hard Problem of Intentionality</strong>.</p>
<h4 id="A-Subjective-“Aboutness”"><a href="#A-Subjective-“Aboutness”" class="headerlink" title="A. Subjective “Aboutness”"></a>A. <strong>Subjective “Aboutness”</strong></h4><p>At the heart of the hard problem is the issue of <strong>subjectivity</strong>. When you have a thought about a tree, that thought is experienced from your <strong>first-person perspective</strong>. It’s not just that brain activity happens; you <strong>experience</strong> that thought as being about something in the world. This subjective experience of “aboutness” seems qualitatively different from the purely physical processes that naturalistic theories describe.</p>
<p>For example:</p>
<ul>
<li>A causal theory might explain that seeing a tree causes certain brain states, but <strong>why does that brain state have the subjective character of “being about a tree”?</strong></li>
<li>Teleosemantics might explain that certain brain processes evolved to represent environmental features for survival, but <strong>how does that give rise to the feeling of “thinking about” something in a first-person, subjective way?</strong></li>
</ul>
<p>This challenge is often compared to the <strong>Hard Problem of Consciousness</strong>, which philosopher <strong>David Chalmers</strong> famously articulated. The hard problem of consciousness asks how **subjective experience (qualia)**—the “what it’s like” aspect of experience—arises from physical processes in the brain. Similarly, the hard problem of intentionality asks how the subjective aspect of intentionality arises from natural processes.</p>
<h4 id="B-Intentionality-as-Normative"><a href="#B-Intentionality-as-Normative" class="headerlink" title="B. Intentionality as Normative"></a>B. <strong>Intentionality as Normative</strong></h4><p>Another element that naturalistic explanations struggle with is the <strong>normativity</strong> of intentionality. Intentional states are not just about things—they can also be <strong>correct</strong> or <strong>incorrect</strong>. For example:</p>
<ul>
<li>If you believe that the sky is blue, and it is blue, your belief is <strong>correct</strong>.</li>
<li>If you believe the sky is green, your belief is <strong>incorrect</strong>.</li>
</ul>
<p>This capacity for mental states to be <strong>evaluated</strong> (correct vs. incorrect) makes intentionality normative—mental states can succeed or fail at representing the world. The hard problem of intentionality asks how <strong>purely physical processes</strong> (which are generally described in <strong>descriptive</strong>, not normative, terms) can give rise to <strong>normative mental properties</strong>.</p>
<h3 id="4-How-is-This-Like-the-Hard-Problem-of-Consciousness"><a href="#4-How-is-This-Like-the-Hard-Problem-of-Consciousness" class="headerlink" title="4. How is This Like the Hard Problem of Consciousness?"></a>4. <strong>How is This Like the Hard Problem of Consciousness?</strong></h3><p>The hard problem of intentionality is closely related to the hard problem of consciousness because both deal with <strong>subjective experience</strong> and its relationship to physical processes. In both cases, naturalistic explanations tend to focus on the <strong>objective</strong>, <strong>third-person</strong> description of processes, but they struggle to account for the <strong>first-person experience</strong> of those processes.</p>
<ul>
<li>The <strong>hard problem of consciousness</strong> asks: “How do <strong>subjective experiences</strong> (what it’s like to feel pain, see red, etc.) arise from the firing of neurons in the brain?”</li>
<li>The <strong>hard problem of intentionality</strong> asks: “How does the mind’s ability to be <em>about</em> things (representing a tree, desiring an outcome, etc.) arise from brain activity and causal relationships?”</li>
</ul>
<p>In both cases, the difficulty is explaining the <strong>qualitative, subjective</strong> aspect of mental life, which seems to resist explanation in terms of <strong>objective physical processes</strong>.</p>
<h3 id="5-Philosophical-Challenges"><a href="#5-Philosophical-Challenges" class="headerlink" title="5. Philosophical Challenges"></a>5. <strong>Philosophical Challenges</strong></h3><p>There are several reasons why naturalizing intentionality faces deep philosophical challenges:</p>
<h4 id="A-The-Explanatory-Gap"><a href="#A-The-Explanatory-Gap" class="headerlink" title="A. The Explanatory Gap"></a>A. <strong>The Explanatory Gap</strong></h4><p>Just as with consciousness, there seems to be an <strong>explanatory gap</strong> between physical processes and the subjective “aboutness” of intentionality. Even if we can fully map the brain processes involved in thinking about a tree, it’s unclear <strong>how</strong> or <strong>why</strong> those processes lead to the experience of <em>“thinking about the tree.”</em></p>
<p>This gap is sometimes described as a <strong>difference in kinds</strong>: physical processes and subjective intentional states are so different in their nature that it’s hard to see how one could reduce to or explain the other.</p>
<h4 id="B-Non-reductive-Views"><a href="#B-Non-reductive-Views" class="headerlink" title="B. Non-reductive Views"></a>B. <strong>Non-reductive Views</strong></h4><p>Some philosophers argue that intentionality, like consciousness, might not be <strong>reducible</strong> to physical processes. <strong>Non-reductive physicalism</strong> or <strong>property dualism</strong> are philosophical views suggesting that while mental states are grounded in the physical, they involve <strong>emergent properties</strong> that cannot be fully explained by physical processes alone.</p>
<p>For instance, <strong>John Searle</strong> argues that while intentionality is a biological feature of the brain, it cannot be reduced to mere causal or functional processes—it’s a higher-level feature that arises from, but isn’t identical to, brain processes.</p>
<h4 id="C-Phenomenology-and-First-Person-Perspective"><a href="#C-Phenomenology-and-First-Person-Perspective" class="headerlink" title="C. Phenomenology and First-Person Perspective"></a>C. <strong>Phenomenology and First-Person Perspective</strong></h4><p><strong>Phenomenologists</strong>, like <strong>Edmund Husserl</strong> and <strong>Maurice Merleau-Ponty</strong>, argue that intentionality can only be fully understood by focusing on the <strong>first-person experience</strong> of being directed toward the world. They believe that trying to reduce intentionality to objective, third-person descriptions (such as causal processes or information flow) misses its core feature: the <strong>lived, subjective experience</strong> of being directed toward the world.</p>
<h3 id="6-Responses-to-the-Hard-Problem-of-Intentionality"><a href="#6-Responses-to-the-Hard-Problem-of-Intentionality" class="headerlink" title="6. Responses to the Hard Problem of Intentionality"></a>6. <strong>Responses to the Hard Problem of Intentionality</strong></h3><p>Some responses to the hard problem of intentionality propose that the subjective aspect of intentionality might not be as intractable as it seems:</p>
<ul>
<li><p><strong>Cognitive Science</strong>: Some cognitive scientists believe that advances in understanding the brain’s <strong>computational processes</strong> will eventually bridge the gap. By explaining how the brain processes information, stores representations, and learns from the environment, they hope to explain the <strong>emergence of intentionality</strong> in a way that accounts for both its subjective and objective aspects.</p>
</li>
<li><p><strong>Emergentism</strong>: Some philosophers suggest that intentionality is an <strong>emergent property</strong> of complex brain systems. While the individual parts of the brain may not be intentional, intentionality may emerge from the complex interaction of those parts. However, explaining how emergence happens in detail remains a challenge.</p>
</li>
<li><p><strong>Panpsychism</strong>: In a more radical response, some philosophers (like <strong>David Chalmers</strong>) propose <strong>panpsychism</strong>, the view that consciousness (and perhaps intentionality) is a fundamental feature of the universe, much like space, time, or matter. In this view, intentionality wouldn’t need to be “reduced” to physical processes because it would be a <strong>basic feature</strong> of reality.</p>
</li>
</ul>
<h3 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. <strong>Conclusion</strong></h3><p>The <strong>Hard Problem of Intentionality</strong> raises profound questions about how the mind represents the world and how subjective mental states can arise from physical processes. While naturalistic theories of intentionality (like causal, teleosemantic, and information-theoretic approaches) have made progress in explaining aspects of mental representation, the <strong>subjective aspect of intentionality</strong>—the first-person experience of “aboutness”—remains elusive. This challenge parallels the <strong>Hard Problem of Consciousness</strong>, leaving open fundamental questions about the nature of the mind and its relationship to the physical world.</p>
]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>nlp-theories</tag>
      </tags>
  </entry>
  <entry>
    <title>Jacobian Matrices</title>
    <url>/nlp-docs/2024/07/17/jacobian-matrices/</url>
    <content><![CDATA[<h3 id="Discussions-on-Jacobian-Matrices-Continued"><a href="#Discussions-on-Jacobian-Matrices-Continued" class="headerlink" title="Discussions on Jacobian Matrices Continued"></a>Discussions on Jacobian Matrices Continued</h3><p>This blog will break down and continue explaining Jacobian matrices and Taylor expansions in plain language and explore how they are connected.</p>
<h4 id="Jacobian-Matrix"><a href="#Jacobian-Matrix" class="headerlink" title="Jacobian Matrix"></a>Jacobian Matrix</h4><p><strong>What it is:</strong></p>
<ul>
<li>Imagine you have a function that takes multiple inputs and gives multiple outputs. For example, you might have a function that takes two numbers (like coordinates $x$ and $y$) and gives back two other numbers.</li>
<li>The Jacobian matrix is a way to capture how small changes in each input affect each output.</li>
</ul>
<p><strong>How it works:</strong></p>
<ul>
<li>Suppose you have a function $f(x, y)$ that gives outputs $u$ and $v$.</li>
<li>The Jacobian matrix for this function is like a grid that shows how $u$ and $v$ change when $x$ and $y$ change.</li>
<li>Mathematically, it’s a 2x2 matrix (in this case) where each entry is a partial derivative. It looks like this:<div class="latex" style="text-align: center">
$$ \text{Jacobian} = \begin{pmatrix}
\frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\
\frac{\partial v}{\partial x} & \frac{\partial v}{\partial y}
\end{pmatrix} $$</li>
</ul>
<p><strong>What it tells you:</strong></p>
<ul>
<li>Each entry in the Jacobian matrix tells you how one output changes with respect to one input.</li>
<li>For instance, $\frac{\partial u}{\partial x}$  tells you how $u$ changes when you make a tiny change in $x$.</li>
</ul>
<h4 id="Taylor-Expansion"><a href="#Taylor-Expansion" class="headerlink" title="Taylor Expansion"></a>Taylor Expansion</h4><p><strong>What it is:</strong></p>
<ul>
<li>The Taylor expansion is a way to approximate a complex function using simpler polynomial terms.</li>
<li>Think of it as breaking down a complicated function into a sum of easy-to-handle pieces.</li>
</ul>
<p><strong>How it works:</strong></p>
<ul>
<li>Suppose you have a function $f(x)$ and you want to approximate it near a point $a$ .</li>
<li>The Taylor expansion uses the value of the function at $a$ and its derivatives (rates of change) at $a$ to build this approximation.</li>
<li>The formula for the Taylor expansion up to the first few terms looks like this:</li>
</ul>
<p>$$ f(x) \approx f(a) + f’(a)(x-a) + \frac{f’’(a)}{2!}(x-a)^2 + \cdots $$</p>
<p><strong>What it tells you:</strong></p>
<ul>
<li>The first term $f(a)$ is the function’s value at $a$ .</li>
<li>The second term $f’(a)(x-a)$ shows how the function changes linearly around $a$ .</li>
<li>The higher-order terms $\frac{f’’(a)}{2!}(x-a)^2$ , etc., show more complex changes (like curvature).</li>
</ul>
<h4 id="Connection-Between-Jacobian-Matrix-and-Taylor-Expansion"><a href="#Connection-Between-Jacobian-Matrix-and-Taylor-Expansion" class="headerlink" title="Connection Between Jacobian Matrix and Taylor Expansion"></a>Connection Between Jacobian Matrix and Taylor Expansion</h4><p><strong>How they are connected:</strong></p>
<ul>
<li>When you use the Taylor expansion for functions with multiple inputs and outputs, the Jacobian matrix comes into play.</li>
<li>For a function with multiple variables, the first-order Taylor expansion looks like this:</li>
</ul>
<p>$$ f(\mathbf{x}) \approx f(\mathbf{a}) + J(\mathbf{a})(\mathbf{x} - \mathbf{a}) $$</p>
<p>  where $\mathbf{x}$ and $\mathbf{a}$ are vectors (like coordinates), and $J(\mathbf{a})$ is the Jacobian matrix at $\mathbf{a}$.</p>
<p><strong>What this means:</strong></p>
<ul>
<li>The Jacobian matrix $J(\mathbf{a})$ captures how the function changes in all directions from the point $\mathbf{a}$.</li>
<li>The term $J(\mathbf{a})(\mathbf{x} - \mathbf{a})$ is like a multi-dimensional linear approximation, showing how small changes in inputs affect the outputs.</li>
</ul>
<p>In summary, the Jacobian matrix gives you a snapshot of how changes in inputs affect outputs for functions with multiple variables. The Taylor expansion uses this information (and higher-order derivatives) to build an approximation of the function near a specific point.</p>
]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>math</tag>
        <tag>determinism</tag>
      </tags>
  </entry>
  <entry>
    <title>Markov Processes</title>
    <url>/nlp-docs/2024/07/16/markov-chains/</url>
    <content><![CDATA[<h3 id="Discussions-on-Markov-Processes-Continued"><a href="#Discussions-on-Markov-Processes-Continued" class="headerlink" title="Discussions on Markov Processes Continued"></a>Discussions on Markov Processes Continued</h3><p>In a different blog, I noted the use of a markov processes in the context of natural language processing. Now in this blog, we will be going through some important details with regard to the concept.</p>
<p>We will go through some code in the subsequent paragraph with respect to how to simulate Markov Chain in coding.</p>
<h4 id="Markov-Chain-Basics"><a href="#Markov-Chain-Basics" class="headerlink" title="Markov Chain Basics"></a>Markov Chain Basics</h4><p>A Markov chain is a mathematical system that undergoes transitions from one state to another within a finite or countable number of states. It is a stochastic process that satisfies the Markov property, which states that the future state depends only on the current state and not on the sequence of events that preceded it.</p>
<h4 id="Components-of-a-Markov-Chain"><a href="#Components-of-a-Markov-Chain" class="headerlink" title="Components of a Markov Chain"></a>Components of a Markov Chain</h4><ol>
<li><p><strong>States</strong>: The different possible conditions or configurations the system can be in.</p>
<ul>
<li>Let’s denote the set of all states as $ S &#x3D; { s_1, s_2, \ldots, s_n } $.</li>
</ul>
</li>
<li><p><strong>Transition Probabilities</strong>: The probabilities of moving from one state to another.</p>
<ul>
<li>Denoted by $ P_{ij} &#x3D; P(X_{t+1} &#x3D; s_j \mid X_t &#x3D; s_i) $, where $ P_{ij} $ is the probability of transitioning from state $ s_i $ to state $ s_j $.</li>
</ul>
</li>
<li><p><strong>Transition Matrix</strong>: A matrix $ P $ where each element $ P_{ij} $ represents the transition probability from state $ s_i $ to state $ s_j $.<br>$$<br>  P &#x3D; \begin{pmatrix}<br>  P_{11} &amp; P_{12} &amp; \cdots &amp; P_{1n} \cr<br>  P_{21} &amp; P_{22} &amp; \cdots &amp; P_{2n} \cr<br>  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \cr<br>  P_{n1} &amp; P_{n2} &amp; \cdots &amp; P_{nn}<br>  \end{pmatrix}<br>$$</p>
</li>
</ol>
<h4 id="Markov-Property"><a href="#Markov-Property" class="headerlink" title="Markov Property"></a>Markov Property</h4><p>The Markov property states that the probability of transitioning to the next state depends only on the current state and not on the past states:<br>$$ P(X_{t+1} &#x3D; s_j \mid X_t &#x3D; s_i, X_{t-1} &#x3D; s_{i-1}, \ldots, X_0 &#x3D; s_0) $$<br>$$ \qquad \quad &#x3D; P(X_{t+1} &#x3D; s_j \mid X_t &#x3D; s_i) $$</p>
<h4 id="Step-by-Step-Process"><a href="#Step-by-Step-Process" class="headerlink" title="Step-by-Step Process"></a>Step-by-Step Process</h4><p>Let’s go through the process of a Markov chain step by step.</p>
<h4 id="Step-1-Define-the-States"><a href="#Step-1-Define-the-States" class="headerlink" title="Step 1: Define the States"></a>Step 1: Define the States</h4><p>Identify all possible states of the system. Suppose we have a simple weather system with three states:</p>
<ul>
<li>$ s_1 $: Sunny</li>
<li>$ s_2 $: Cloudy</li>
<li>$ s_3 $: Rainy</li>
</ul>
<h4 id="Step-2-Define-the-Transition-Probabilities"><a href="#Step-2-Define-the-Transition-Probabilities" class="headerlink" title="Step 2: Define the Transition Probabilities"></a>Step 2: Define the Transition Probabilities</h4><p>Determine the probabilities of moving from one state to another. For example, the transition probabilities might be:</p>
<ul>
<li>$ P_{11} &#x3D; 0.7 $ (probability of sunny to sunny)</li>
<li>$ P_{12} &#x3D; 0.2 $ (probability of sunny to cloudy)</li>
<li>$ P_{13} &#x3D; 0.1 $ (probability of sunny to rainy)</li>
<li>$ P_{21} &#x3D; 0.3 $ (probability of cloudy to sunny)</li>
<li>$ P_{22} &#x3D; 0.4 $ (probability of cloudy to cloudy)</li>
<li>$ P_{23} &#x3D; 0.3 $ (probability of cloudy to rainy)</li>
<li>$ P_{31} &#x3D; 0.2 $ (probability of rainy to sunny)</li>
<li>$ P_{32} &#x3D; 0.3 $ (probability of rainy to cloudy)</li>
<li>$ P_{33} &#x3D; 0.5 $ (probability of rainy to rainy)</li>
</ul>
<p>These can be represented in the transition matrix $ P $:</p>
<p>$$ P &#x3D; \begin{pmatrix}<br>    0.7 &amp; 0.2 &amp; 0.1 \cr<br>    0.3 &amp; 0.4 &amp; 0.3 \cr<br>    0.2 &amp; 0.3 &amp; 0.5<br>\end{pmatrix} $$</p>
<h4 id="Step-3-Initial-State-Distribution"><a href="#Step-3-Initial-State-Distribution" class="headerlink" title="Step 3: Initial State Distribution"></a>Step 3: Initial State Distribution</h4><p>Define the initial state distribution vector $ \pi $, which represents the probability distribution of starting in each state. For example, if we start with a 100% chance of it being sunny:</p>
<p>$$ \pi &#x3D; \begin{pmatrix}<br>    1 \cr<br>    0 \cr<br>    0<br>\end{pmatrix} $$</p>
<h4 id="Step-4-State-Prediction"><a href="#Step-4-State-Prediction" class="headerlink" title="Step 4: State Prediction"></a>Step 4: State Prediction</h4><p>To predict the state distribution after one step, multiply the initial state distribution vector $ \pi $ by the transition matrix $ P $:</p>
<p>$$ \pi^{(1)} &#x3D; \pi P $$</p>
<p>$$ \pi^{(1)} &#x3D; \begin{pmatrix}<br>    1 &amp; 0 &amp; 0<br>\end{pmatrix}  \begin{pmatrix}<br>    0.7 &amp; 0.2 &amp; 0.1 \cr<br>    0.3 &amp; 0.4 &amp; 0.3 \cr<br>    0.2 &amp; 0.3 &amp; 0.5<br>\end{pmatrix} $$</p>
<p>$$ \pi^{(1)} &#x3D; \begin{pmatrix}<br>    0.7 &amp; 0.2 &amp; 0.1<br>\end{pmatrix} $$</p>
<p>This tells us that after one step, there’s a 70% chance of it being sunny, a 20% chance of it being cloudy, and a 10% chance of it being rainy.</p>
<h4 id="Step-5-Long-Term-Behavior"><a href="#Step-5-Long-Term-Behavior" class="headerlink" title="Step 5: Long-Term Behavior"></a>Step 5: Long-Term Behavior</h4><p>To find the steady-state distribution (long-term behavior), solve for $ \pi $ in the equation:<br>$ \pi P &#x3D; \pi $<br>This often involves solving a system of linear equations. The steady-state distribution is the vector $ \pi $ that remains unchanged after application of the transition matrix $ P $.</p>
<h4 id="Example-Calculation"><a href="#Example-Calculation" class="headerlink" title="Example Calculation"></a>Example Calculation</h4><p>If we continue the prediction for multiple steps, we can see how the state distribution evolves over time. For example, after two steps:</p>
<p>$$ \pi^{(2)} &#x3D; \pi^{(1)} P $$</p>
<p>$$ \pi^{(2)} &#x3D; \begin{pmatrix}<br>    0.7 &amp; 0.2 &amp; 0.1<br>\end{pmatrix} \begin{pmatrix}<br>    0.7 &amp; 0.2 &amp; 0.1 \cr<br>    0.3 &amp; 0.4 &amp; 0.3 \cr<br>    0.2 &amp; 0.3 &amp; 0.5<br>\end{pmatrix} $$</p>
<p>$$ \pi^{(2)} &#x3D; \begin{pmatrix}<br>  0.7 \cdot 0.7 + 0.2 \cdot 0.3 + 0.1 \cdot 0.2 \cr<br>  0.7 \cdot 0.2 + 0.2 \cdot 0.4 + 0.1 \cdot 0.3 \cr<br>  0.7 \cdot 0.1 + 0.2 \cdot 0.3 + 0.1 \cdot 0.5<br>\end{pmatrix} $$</p>
<p>$$ \pi^{(2)} &#x3D; \begin{pmatrix}<br>    0.53 &amp; 0.26 &amp; 0.21<br>\end{pmatrix} $$</p>
<p>So after two steps, there’s a 53% chance of it being sunny, a 26% chance of it being cloudy, and a 21% chance of it being rainy.</p>
<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p>A Markov chain is a powerful tool for modeling stochastic processes where the next state depends only on the current state. The key components include states, transition probabilities, and the transition matrix. The process involves defining the states and transition probabilities, computing state predictions, and analyzing long-term behavior through steady-state distributions.</p>
<p>In this example, we define a transition matrix P for a 3-state Markov process. We then define a function simulate_markov that takes the transition matrix, the number of states, and the number of steps to simulate as input, and returns a list of the system’s states at each time step.</p>
<p>The function initializes the state vector to all zeros, with a 1 in the first position to indicate that the system starts in state 0. It then simulates the Markov process by iteratively selecting the next state based on the current state and the transition probabilities. The current state is added to a history list at each time step.</p>
<p>Finally, we simulate the Markov process for 100 steps and print the resulting state history.</p>
<h3 id="In-What-Scenarios-Is-Markov-Chain-Applicable"><a href="#In-What-Scenarios-Is-Markov-Chain-Applicable" class="headerlink" title="In What Scenarios Is Markov Chain Applicable?"></a>In What Scenarios Is Markov Chain Applicable?</h3><p>Simulating all these processes using Markov processes can be quite extensive. However, I can provide a basic framework and example for a few of these applications, demonstrating how Markov processes can be applied. We will use Python and some common libraries such as NumPy for these simulations.</p>
<p>This section breaks down a simple example of how to build a simple markov chain in code example.</p>
<p>Sure! Here’s an updated version of all the examples where we retain the <strong>calculated state vector</strong> (probability distribution) between steps, avoiding the unnecessary reset to a one-hot encoded vector.</p>
<h3 id="Updated-Example-1-Modeling-Stock-Prices-with-Dot-Product"><a href="#Updated-Example-1-Modeling-Stock-Prices-with-Dot-Product" class="headerlink" title="Updated Example 1: Modeling Stock Prices with Dot Product"></a>Updated Example 1: Modeling Stock Prices with Dot Product</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define states (price levels)</span></span><br><span class="line">states = np.array([<span class="number">90</span>, <span class="number">100</span>, <span class="number">110</span>, <span class="number">120</span>])</span><br><span class="line">n_states = <span class="built_in">len</span>(states)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the transition matrix</span></span><br><span class="line">P = np.array([</span><br><span class="line">    [<span class="number">0.7</span>, <span class="number">0.2</span>, <span class="number">0.1</span>, <span class="number">0.0</span>],  <span class="comment"># From 90</span></span><br><span class="line">    [<span class="number">0.1</span>, <span class="number">0.7</span>, <span class="number">0.2</span>, <span class="number">0.0</span>],  <span class="comment"># From 100</span></span><br><span class="line">    [<span class="number">0.0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>],  <span class="comment"># From 110</span></span><br><span class="line">    [<span class="number">0.0</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.7</span>],  <span class="comment"># From 120</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initial state (one-hot vector for state 100)</span></span><br><span class="line">state_vector = np.zeros(n_states)</span><br><span class="line">state_vector[<span class="number">1</span>] = <span class="number">1</span>  <span class="comment"># Start in state 100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of steps to simulate</span></span><br><span class="line">n_steps = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Track price history</span></span><br><span class="line">price_history = [states[np.argmax(state_vector)]]  <span class="comment"># Start price history</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_steps):</span><br><span class="line">    <span class="comment"># Perform dot product to get the next state probabilities</span></span><br><span class="line">    state_vector = np.dot(state_vector, P)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Choose the next state based on the resulting probabilities</span></span><br><span class="line">    next_state = np.random.choice(n_states, p=state_vector)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the price history for the next state</span></span><br><span class="line">    price_history.append(states[next_state])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the results</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(price_history)</span><br><span class="line">plt.title(<span class="string">&#x27;Simulated Stock Prices Using Markov Process with Dot Product&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Time Steps&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Price&#x27;</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Updated-Example-2-Disease-Progression-with-Dot-Product"><a href="#Updated-Example-2-Disease-Progression-with-Dot-Product" class="headerlink" title="Updated Example 2: Disease Progression with Dot Product"></a>Updated Example 2: Disease Progression with Dot Product</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define states (health conditions)</span></span><br><span class="line">states = [<span class="string">&quot;Healthy&quot;</span>, <span class="string">&quot;Sick&quot;</span>, <span class="string">&quot;Recovered&quot;</span>]</span><br><span class="line">n_states = <span class="built_in">len</span>(states)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the transition matrix</span></span><br><span class="line">P = np.array([</span><br><span class="line">    [<span class="number">0.85</span>, <span class="number">0.10</span>, <span class="number">0.05</span>],  <span class="comment"># From Healthy</span></span><br><span class="line">    [<span class="number">0.15</span>, <span class="number">0.70</span>, <span class="number">0.15</span>],  <span class="comment"># From Sick</span></span><br><span class="line">    [<span class="number">0.05</span>, <span class="number">0.10</span>, <span class="number">0.85</span>],  <span class="comment"># From Recovered</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initial state (one-hot vector for Healthy)</span></span><br><span class="line">state_vector = np.zeros(n_states)</span><br><span class="line">state_vector[<span class="number">0</span>] = <span class="number">1</span>  <span class="comment"># Start as Healthy</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of steps to simulate</span></span><br><span class="line">n_steps = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Track health history</span></span><br><span class="line">health_history = [states[np.argmax(state_vector)]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_steps):</span><br><span class="line">    <span class="comment"># Perform dot product to get the next state probabilities</span></span><br><span class="line">    state_vector = np.dot(state_vector, P)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Choose the next state based on the resulting probabilities</span></span><br><span class="line">    next_state = np.random.choice(n_states, p=state_vector)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the health history</span></span><br><span class="line">    health_history.append(states[next_state])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the results</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Health Condition Over Time:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; -&gt; &quot;</span>.join(health_history))</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Updated-Example-3-Queueing-Systems-with-Dot-Product"><a href="#Updated-Example-3-Queueing-Systems-with-Dot-Product" class="headerlink" title="Updated Example 3: Queueing Systems with Dot Product"></a>Updated Example 3: Queueing Systems with Dot Product</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define states (number of customers in queue)</span></span><br><span class="line">states = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]  <span class="comment"># Queue capacity is 5</span></span><br><span class="line">n_states = <span class="built_in">len</span>(states)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the transition matrix</span></span><br><span class="line">P = np.array([</span><br><span class="line">    [<span class="number">0.1</span>, <span class="number">0.9</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],  <span class="comment"># From 0 customers</span></span><br><span class="line">    [<span class="number">0.5</span>, <span class="number">0.4</span>, <span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],  <span class="comment"># From 1 customer</span></span><br><span class="line">    [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],  <span class="comment"># From 2 customers</span></span><br><span class="line">    [<span class="number">0.0</span>, <span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],  <span class="comment"># From 3 customers</span></span><br><span class="line">    [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.1</span>, <span class="number">0.0</span>],  <span class="comment"># From 4 customers</span></span><br><span class="line">    [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.5</span>, <span class="number">0.4</span>, <span class="number">0.1</span>],  <span class="comment"># From 5 customers</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initial state (one-hot vector for an empty queue)</span></span><br><span class="line">state_vector = np.zeros(n_states)</span><br><span class="line">state_vector[<span class="number">0</span>] = <span class="number">1</span>  <span class="comment"># Start with empty queue</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of steps to simulate</span></span><br><span class="line">n_steps = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Track queue history</span></span><br><span class="line">queue_history = [states[np.argmax(state_vector)]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_steps):</span><br><span class="line">    <span class="comment"># Perform dot product to get the next state probabilities</span></span><br><span class="line">    state_vector = np.dot(state_vector, P)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Choose the next state based on the resulting probabilities</span></span><br><span class="line">    next_state = np.random.choice(n_states, p=state_vector)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the queue history</span></span><br><span class="line">    queue_history.append(states[next_state])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the results</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(queue_history)</span><br><span class="line">plt.title(<span class="string">&#x27;Simulated Queue Length Using Markov Process with Dot Product&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Time Steps&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Number of Customers in Queue&#x27;</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Updated-Example-4-Customer-Loyalty-with-Dot-Product"><a href="#Updated-Example-4-Customer-Loyalty-with-Dot-Product" class="headerlink" title="Updated Example 4: Customer Loyalty with Dot Product"></a>Updated Example 4: Customer Loyalty with Dot Product</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define states (customer states)</span></span><br><span class="line">states = [<span class="string">&quot;Active&quot;</span>, <span class="string">&quot;Inactive&quot;</span>, <span class="string">&quot;Loyal&quot;</span>]</span><br><span class="line">n_states = <span class="built_in">len</span>(states)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the transition matrix</span></span><br><span class="line">P = np.array([</span><br><span class="line">    [<span class="number">0.7</span>, <span class="number">0.2</span>, <span class="number">0.1</span>],  <span class="comment"># From Active</span></span><br><span class="line">    [<span class="number">0.3</span>, <span class="number">0.6</span>, <span class="number">0.1</span>],  <span class="comment"># From Inactive</span></span><br><span class="line">    [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.7</span>],  <span class="comment"># From Loyal</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initial state (one-hot vector for Active)</span></span><br><span class="line">state_vector = np.zeros(n_states)</span><br><span class="line">state_vector[<span class="number">0</span>] = <span class="number">1</span>  <span class="comment"># Start as Active</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of steps to simulate</span></span><br><span class="line">n_steps = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Track loyalty history</span></span><br><span class="line">loyalty_history = [states[np.argmax(state_vector)]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_steps):</span><br><span class="line">    <span class="comment"># Perform dot product to get the next state probabilities</span></span><br><span class="line">    state_vector = np.dot(state_vector, P)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Choose the next state based on the resulting probabilities</span></span><br><span class="line">    next_state = np.random.choice(n_states, p=state_vector)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the loyalty history</span></span><br><span class="line">    loyalty_history.append(states[next_state])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the results</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Customer Loyalty Over Time:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; -&gt; &quot;</span>.join(loyalty_history))</span><br></pre></td></tr></table></figure>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><p>This framework can be extended to simulate other processes like economic forecasting, pharmacokinetics, network protocols, etc.</p>
<p>Each simulation contains these properties:</p>
<table>
<thead>
<tr>
<th>Number</th>
<th>Concept</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>1.</td>
<td><strong>States</strong></td>
<td>A system can exist in different states, representing distinct configurations or conditions. Denoted by symbols, numbers, or labels.</td>
</tr>
<tr>
<td>2.</td>
<td><strong>Transition Probabilities</strong></td>
<td>Markov processes are characterized by transition probabilities, which determine the likelihood of moving from one state to another in the next time step. These probabilities are often organized into a transition probability matrix.</td>
</tr>
<tr>
<td>3.</td>
<td><strong>Transition Probability Matrix</strong></td>
<td>A square matrix where each element represents the probability of transitioning from one state to another. Rows correspond to the current state, and columns correspond to the next state.</td>
</tr>
<tr>
<td>4.</td>
<td><strong>Markov Property</strong></td>
<td>The key feature of Markov processes is the Markov property, stating that the future evolution of the system depends only on its current state and is independent of how the system reached its current state.</td>
</tr>
<tr>
<td>5.</td>
<td><strong>Homogeneity</strong></td>
<td>Markov processes are often assumed to be homogeneous, meaning that transition probabilities do not change over time. The system’s dynamics are consistent throughout.</td>
</tr>
<tr>
<td>6.</td>
<td><strong>Continuous and Discrete Time</strong></td>
<td>Markov processes can be classified into continuous-time and discrete-time processes based on whether the state transitions occur at every instant or at discrete time intervals.</td>
</tr>
<tr>
<td>7.</td>
<td><strong>Stationary Distribution</strong></td>
<td>In a steady state, the system may reach a stationary distribution, where the probabilities of being in each state remain constant over time.</td>
</tr>
<tr>
<td>8.</td>
<td><strong>Absorbing and Transient States</strong></td>
<td>Some states may be absorbing, meaning that once entered, the system stays in that state permanently. Transient states are those from which the system may leave and not return.</td>
</tr>
<tr>
<td>9.</td>
<td><strong>Applications</strong></td>
<td>Markov processes find applications in various fields, including physics, economics, biology, and computer science, for modeling dynamic systems with probabilistic transitions.</td>
</tr>
<tr>
<td>10.</td>
<td><strong>Markov Chain</strong></td>
<td>A specific type of Markov process where the state space is discrete and the time parameter takes on discrete values.</td>
</tr>
</tbody></table>
<p>This basic approach can be adapted and extended to suit the specific characteristics and requirements of each application.</p>
<h4 id="Markov-Chain"><a href="#Markov-Chain" class="headerlink" title="Markov Chain"></a>Markov Chain</h4><p>A Markov chain is a specific type of Markov process that deals with discrete states and discrete time steps. It is characterized by the following:</p>
<ol>
<li><strong>Discrete State Space</strong>: The set of possible states $ S &#x3D; {s_1, s_2, \ldots, s_n} $ is finite or countable.</li>
<li><strong>Discrete Time Steps</strong>: The process evolves in discrete time steps $ t &#x3D; 0, 1, 2, \ldots $.</li>
<li><strong>Markov Property</strong>: The probability of transitioning to the next state depends only on the current state and not on the sequence of events that preceded it.</li>
</ol>
<h6 id="Formal-Definition"><a href="#Formal-Definition" class="headerlink" title="Formal Definition"></a>Formal Definition</h6><p>A Markov chain is defined by:</p>
<ul>
<li>A set of states $ S $.</li>
<li>A transition probability matrix $ P $, where $ P_{ij} $ represents the probability of moving from state $ s_i $ to state $ s_j $. The full formula looks like below.</li>
</ul>
<p>$$ P(X_{t+1} &#x3D; s_j \mid X_t &#x3D; s_i) &#x3D; P_{ij} $$</p>
<h4 id="Markov-Process"><a href="#Markov-Process" class="headerlink" title="Markov Process"></a>Markov Process</h4><p>A Markov process is a more general concept that includes both discrete and continuous cases. It is characterized by:</p>
<ol>
<li><strong>State Space</strong>: The set of possible states can be discrete (finite or countable) or continuous.</li>
<li><strong>Time Steps</strong>: The process can evolve in either discrete time steps (like in a Markov chain) or continuous time.</li>
<li><strong>Markov Property</strong>: Similar to the Markov chain, the future state depends only on the current state and not on past states.</li>
</ol>
<h4 id="Types-of-Markov-Processes"><a href="#Types-of-Markov-Processes" class="headerlink" title="Types of Markov Processes"></a>Types of Markov Processes</h4><ol>
<li><p><strong>Discrete-Time Markov Process (Markov Chain)</strong>:</p>
<ul>
<li>As described above, it deals with discrete states and discrete time steps.</li>
</ul>
</li>
<li><p><strong>Continuous-Time Markov Process</strong>:</p>
<ul>
<li>The state space can be discrete or continuous.</li>
<li>The process evolves continuously over time.</li>
<li>Transition probabilities are often described using a rate matrix (or generator matrix) instead of a transition matrix.</li>
</ul>
</li>
</ol>
<p><strong>Continuous-Time Markov Chain (CTMC)</strong></p>
<p>A CTMC is a specific type of Markov process where:</p>
<p>· The state space is discrete.<br>· Time is continuous.<br>· The transitions are governed by rates, often described using a rate matrix $ Q $.</p>
<h4 id="Summary-of-Differences"><a href="#Summary-of-Differences" class="headerlink" title="Summary of Differences"></a>Summary of Differences</h4><ul>
<li><p><strong>State Space</strong>:</p>
<ul>
<li><strong>Markov Chain</strong>: Discrete state space.</li>
<li><strong>Markov Process</strong>: Can be discrete or continuous state space.</li>
</ul>
</li>
<li><p><strong>Time</strong>:</p>
<ul>
<li><strong>Markov Chain</strong>: Discrete time steps.</li>
<li><strong>Markov Process</strong>: Can be discrete or continuous time.</li>
</ul>
</li>
<li><p><strong>Transition Mechanism</strong>:</p>
<ul>
<li><strong>Markov Chain</strong>: Defined by a transition probability matrix.</li>
<li><strong>Markov Process</strong>: Defined by transition probabilities for discrete time or transition rates for continuous time.</li>
</ul>
</li>
</ul>
<h4 id="Markov-Chain-Discrete-Time-Discrete-State"><a href="#Markov-Chain-Discrete-Time-Discrete-State" class="headerlink" title="Markov Chain (Discrete-Time, Discrete State)"></a>Markov Chain (Discrete-Time, Discrete State)</h4><p>Consider a simple weather model with three states: Sunny, Cloudy, and Rainy. The transitions are defined for each day (discrete time steps).</p>
<ul>
<li><p>States: $ S &#x3D; { \text{Sunny}, \text{Cloudy}, \text{Rainy} } $</p>
</li>
<li><p>Transition Matrix $ P $:</p>
<p>$$<br>P &#x3D; \begin{pmatrix}<br>0.7 &amp; 0.2 &amp; 0.1 \cr<br>0.3 &amp; 0.4 &amp; 0.3 \cr<br>0.2 &amp; 0.3 &amp; 0.5<br>\end{pmatrix}<br>$$</p>
</li>
</ul>
<h4 id="Continuous-Time-Markov-Process-Continuous-Time-Discrete-State"><a href="#Continuous-Time-Markov-Process-Continuous-Time-Discrete-State" class="headerlink" title="Continuous-Time Markov Process (Continuous-Time, Discrete State)"></a>Continuous-Time Markov Process (Continuous-Time, Discrete State)</h4><p>Consider a population model where individuals can be in different health states: Healthy, Sick, and Recovered. The transitions happen continuously over time, with certain rates.</p>
<ul>
<li><p>States: $ S &#x3D; { \text{Healthy}, \text{Sick}, \text{Recovered} } $</p>
</li>
<li><p>Rate Matrix $ Q $:</p>
<p>$$<br>Q &#x3D; \begin{pmatrix}<br>-\lambda &amp; \lambda &amp; 0 \cr<br>0 &amp; -\mu &amp; \mu \cr<br>0 &amp; 0 &amp; 0<br>\end{pmatrix}<br>$$</p>
</li>
</ul>
<p>where $\lambda$ is the rate of getting sick, and $\mu$ is the rate of recovery.</p>
<p>In summary, a Markov chain is a special case of a Markov process with discrete states and discrete time steps, whereas a Markov process can have a broader definition, encompassing both discrete and continuous states and time.</p>
]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>math</tag>
        <tag>stochastic</tag>
      </tags>
  </entry>
  <entry>
    <title>Contemporary NLP</title>
    <url>/nlp-docs/2024/08/13/mdn-nlp/</url>
    <content><![CDATA[<h3 id="Introduction-to-Contemporary-NLP"><a href="#Introduction-to-Contemporary-NLP" class="headerlink" title="Introduction to Contemporary NLP"></a>Introduction to Contemporary NLP</h3><p><span class="label label-danger">Q</span> What is the importance of psychological concepts in NLP?</p>
<p><span class="label label-success">A</span> To understand modern natural language processing (NLP), it’s essential to draw inferences from crucial psychological concepts like the <strong>Language of Thought Hypothesis</strong> and the <strong>Representational Theory of Mind</strong>. These concepts help explain how our brain processes and produces language and mental representations, which are foundational for NLP.</p>
<h6 id="Language-of-Thought-Hypothesis-LOTH"><a href="#Language-of-Thought-Hypothesis-LOTH" class="headerlink" title="Language of Thought Hypothesis (LOTH)"></a>Language of Thought Hypothesis (<code>LOTH</code>)</h6><p><span class="label label-danger">Q</span> What does the Language of Thought Hypothesis (<code>LOTH</code>) propose?</p>
<p><span class="label label-success">A</span> <code>LOTH</code> proposes that our brain has a schema for producing language of thought, known as <em>Mentalese</em>. It suggests that mental states and thoughts have a structured, language-like format, which facilitates reasoning, problem-solving, and decision-making.</p>
<p><span class="label label-danger">Q</span> What are propositional attitudes in <code>LOTH</code>?</p>
<p><span class="label label-success">A</span> Propositional attitudes in <code>LOTH</code> refer to the mental states that involve a relationship between a person and a proposition, such as beliefs, desires, and intentions. These attitudes are expressed through mental representations and are essential for inferential reasoning.</p>
<h6 id="Representational-Theory-of-Mind"><a href="#Representational-Theory-of-Mind" class="headerlink" title="Representational Theory of Mind"></a>Representational Theory of Mind</h6><p><span class="label label-danger">Q</span> How does the Representational Theory of Mind relate to <code>LOTH</code>?</p>
<p><span class="label label-success">A</span> The Representational Theory of Mind (RTM) supports <code>LOTH</code> by emphasizing that our cognitive abilities, such as conscious decision-making and problem-solving, are based on mental representations. These representations can be analyzed through the semantics of natural language and are crucial for understanding mental processes.</p>
<h6 id="Compositionality-of-Mental-Processes-COMP"><a href="#Compositionality-of-Mental-Processes-COMP" class="headerlink" title="Compositionality of Mental Processes (COMP)"></a>Compositionality of Mental Processes (<code>COMP</code>)</h6><p><span class="label label-danger">Q</span> What is the Compositionality of Mental Processes (<code>COMP</code>)?</p>
<p><span class="label label-success">A</span> <code>COMP</code> suggests that mental states have constituent structures similar to natural language. This means that complex thoughts are composed of simpler mental representations, just as complex sentences are formed from simpler linguistic expressions.</p>
<p><span class="label label-danger">Q</span> How do ancient and modern researchers differ in their approach to <code>COMP</code>?</p>
<p><span class="label label-success">A</span> Ancient proponents of <code>LOTH</code> used syllogism and propositional logic to analyze the semantics of <em>Mentalese</em>, while modern researchers use predicate calculus and other formal systems to study the compositional nature of mental representations.</p>
<h6 id="Concept-Acquisition-in-Language-Learning"><a href="#Concept-Acquisition-in-Language-Learning" class="headerlink" title="Concept Acquisition in Language Learning"></a>Concept Acquisition in Language Learning</h6><p><span class="label label-danger">Q</span> How do infants acquire concepts according to hypothesis formulation?</p>
<p><span class="label label-success">A</span> Infants form hypotheses about the world based on their observations and experiences. They test these hypotheses through interactions with their environment, updating their understanding of concepts like gravity through a process of hypothesis testing and model refinement.</p>
<h6 id="Type-Token-Relation-of-Mental-Representations"><a href="#Type-Token-Relation-of-Mental-Representations" class="headerlink" title="Type-Token Relation of Mental Representations"></a>Type-Token Relation of Mental Representations</h6><p><span class="label label-danger">Q</span> What is the type-token relation in mental representations?</p>
<p><span class="label label-success">A</span> The type-token relation distinguishes between different instances (tokens) of the same mental representation (type). For example, two instances of the word “cat” in different contexts are tokens of the same type in <em>Mentalese</em>.</p>
<h6 id="More-on-Type-Token-Identity-Theory"><a href="#More-on-Type-Token-Identity-Theory" class="headerlink" title="More on Type-Token Identity Theory"></a>More on Type-Token Identity Theory</h6><p><span class="label label-danger">Q</span> What is the Token-Type Identity Theory?</p>
<p><span class="label label-success">A</span> The Token-Type Identity Theory is a perspective in philosophy of mind that suggests that mental states and processes are identical to specific physical states and processes in the brain. According to this theory, each mental state (a token) is a unique instance of a physical state (a type) in the brain.</p>
<h6 id="Type-and-Token"><a href="#Type-and-Token" class="headerlink" title="Type and Token"></a>Type and Token</h6><p><span class="label label-danger">Q</span> What is the difference between a type and a token in this theory?</p>
<p><span class="label label-success">A</span> In the context of Token-Type Identity Theory:</p>
<ul>
<li>A <strong>type</strong> refers to a general category or class of mental states, such as the concept of “pain” or “belief.”</li>
<li>A <strong>token</strong> is a specific instance of a type, such as a particular feeling of pain or a specific belief held by an individual at a given moment.</li>
</ul>
<h6 id="Relation-to-Mental-States"><a href="#Relation-to-Mental-States" class="headerlink" title="Relation to Mental States"></a>Relation to Mental States</h6><p><span class="label label-danger">Q</span> How does Token-Type Identity Theory relate to mental states?</p>
<p><span class="label label-success">A</span> The theory posits that every mental state is a token of a specific type of physical state in the brain. For example, the mental state of feeling happy is identical to a particular pattern of neural activity in the brain, which is a token of the broader type of neural patterns associated with happiness.</p>
<h6 id="Advantages-of-the-Theory"><a href="#Advantages-of-the-Theory" class="headerlink" title="Advantages of the Theory"></a>Advantages of the Theory</h6><p><span class="label label-danger">Q</span> What are the advantages of Token-Type Identity Theory?</p>
<p><span class="label label-success">A</span> Some advantages of Token-Type Identity Theory include:</p>
<ul>
<li><strong>Scientific Alignment</strong>: It aligns with scientific research in neuroscience that links mental processes to brain activity.</li>
<li><strong>Simplicity</strong>: It offers a straightforward explanation of the mind-body relationship by equating mental states with physical states.</li>
<li><strong>Reductionism</strong>: It supports a reductionist approach, which aims to explain complex phenomena in terms of simpler physical processes.</li>
</ul>
<h6 id="Multiple-Realizability-Challenge"><a href="#Multiple-Realizability-Challenge" class="headerlink" title="Multiple Realizability Challenge"></a>Multiple Realizability Challenge</h6><p><span class="label label-danger">Q</span> What is the challenge of multiple realizability in Token-Type Identity Theory?</p>
<p><span class="label label-success">A</span> The challenge of multiple realizability refers to the idea that the same mental state (type) can be realized by different physical states (tokens) in different individuals or species. For example, the mental state of pain might correspond to different neural configurations in humans, animals, or artificial intelligence, challenging the one-to-one correspondence proposed by Token-Type Identity Theory.</p>
<h6 id="Functionalism-as-an-Alternative"><a href="#Functionalism-as-an-Alternative" class="headerlink" title="Functionalism as an Alternative"></a>Functionalism as an Alternative</h6><p><span class="label label-danger">Q</span> How does functionalism address the challenge of multiple realizability?</p>
<p><span class="label label-success">A</span> Functionalism offers an alternative to Token-Type Identity Theory by defining mental states in terms of their functional roles rather than their physical substrates. According to functionalism, a mental state is identified by what it does rather than what it is made of, allowing for multiple realizations of the same mental state across different physical systems.</p>
<h6 id="Historical-Context"><a href="#Historical-Context" class="headerlink" title="Historical Context"></a>Historical Context</h6><p><span class="label label-danger">Q</span> What is the historical context of Token-Type Identity Theory?</p>
<p><span class="label label-success">A</span> Token-Type Identity Theory emerged in the mid-20th century as part of the broader identity theory movement in philosophy of mind. It was developed in response to the limitations of dualism and behaviorism, offering a more scientifically grounded approach to understanding the mind-body relationship.</p>
<h6 id="Examples-and-Applications"><a href="#Examples-and-Applications" class="headerlink" title="Examples and Applications"></a>Examples and Applications</h6><p><span class="label label-danger">Q</span> Can you provide examples of Token-Type Identity Theory in practice?</p>
<p><span class="label label-success">A</span> Examples of Token-Type Identity Theory include:</p>
<ul>
<li><strong>Pain</strong>: A specific neural pattern in the brain that corresponds to the feeling of pain is a token of the type “pain.”</li>
<li><strong>Belief</strong>: A particular neural configuration associated with the belief that “the sky is blue” is a token of the type “belief.”</li>
</ul>
<h6 id="Criticisms"><a href="#Criticisms" class="headerlink" title="Criticisms"></a>Criticisms</h6><p><span class="label label-danger">Q</span> What are some criticisms of Token-Type Identity Theory?</p>
<p><span class="label label-success">A</span> Criticisms of Token-Type Identity Theory include:</p>
<ul>
<li><strong>Multiple Realizability</strong>: The theory struggles to account for the fact that the same mental state can be realized by different physical states.</li>
<li><strong>Subjectivity</strong>: It may overlook the subjective, qualitative aspects of mental experiences (qualia) that are difficult to reduce to physical states.</li>
<li><strong>Reductionism</strong>: Some argue that reducing mental states to physical states oversimplifies the complexity of human cognition and consciousness.</li>
</ul>
<h6 id="Modern-Developments"><a href="#Modern-Developments" class="headerlink" title="Modern Developments"></a>Modern Developments</h6><p><span class="label label-danger">Q</span> How has Token-Type Identity Theory evolved in modern philosophy?</p>
<p><span class="label label-success">A</span> In modern philosophy, Token-Type Identity Theory has evolved to incorporate insights from neuroscience and cognitive science. While some philosophers continue to defend the theory, others have developed more nuanced approaches that address its limitations, such as non-reductive physicalism and emergentism.</p>
<h6 id="Connectionism-in-NLP"><a href="#Connectionism-in-NLP" class="headerlink" title="Connectionism in NLP"></a>Connectionism in NLP</h6><p><span class="label label-danger">Q</span> What is connectionism and how does it differ from traditional computational models?</p>
<p><span class="label label-success">A</span> Connectionism is an approach that models cognitive processes through networks of interconnected units, similar to neurons in the brain. Unlike traditional symbolic models, connectionist models use distributed representations and learn from experience, providing a more biologically plausible way to emulate brain activity.</p>
<h6 id="COMP-and-Syntactic-Structures"><a href="#COMP-and-Syntactic-Structures" class="headerlink" title="COMP and Syntactic Structures"></a><code>COMP</code> and Syntactic Structures</h6><p><span class="label label-danger">Q</span> How does Chomsky’s Transformational Grammar Theory relate to <code>COMP</code>?</p>
<p><span class="label label-success">A</span> Chomsky’s Transformational Grammar Theory demonstrates how complex syntactic structures in natural language can be generated through transformations applied to underlying structures. This theory aligns with <code>COMP</code> by showing how simple linguistic expressions combine to form complex sentences.</p>
<h6 id="Statistical-Semantics-in-NLP"><a href="#Statistical-Semantics-in-NLP" class="headerlink" title="Statistical Semantics in NLP"></a>Statistical Semantics in NLP</h6><p><span class="label label-danger">Q</span> How did statistical NLP change the field of natural language processing?</p>
<p><span class="label label-success">A</span> Statistical NLP introduced probabilistic models and corpus-based approaches, allowing researchers to systematically exploit the distributional properties of language. This shift made it possible to develop more scalable and accurate models for tasks like speech recognition, part-of-speech tagging, and machine translation.</p>
<h6 id="Techniques-in-Statistical-NLP"><a href="#Techniques-in-Statistical-NLP" class="headerlink" title="Techniques in Statistical NLP"></a>Techniques in Statistical NLP</h6><p><span class="label label-danger">Q</span> What are some key techniques used in statistical NLP?</p>
<p><span class="label label-success">A</span> Key techniques in statistical NLP include:</p>
<ul>
<li><strong>TF-IDF Normalization</strong>: Assigning weights to words based on their frequency in the document and rarity across the corpus.</li>
<li><strong>Bayesian Approach</strong>: Using probabilistic models to classify text.</li>
<li><strong>Sequence Models and HMMs</strong>: Capturing dependencies in text sequences.</li>
<li><strong>kNN Method and Decision Trees</strong>: Classifying text based on nearest neighbors or decision rules.</li>
<li><strong>MaxEnt (Logistic Regression) and SVM</strong>: Using advanced statistical models for classification.</li>
</ul>
<h6 id="Connectionism-and-Deep-Neural-Networks"><a href="#Connectionism-and-Deep-Neural-Networks" class="headerlink" title="Connectionism and Deep Neural Networks"></a>Connectionism and Deep Neural Networks</h6><p><span class="label label-danger">Q</span> How have neural networks evolved in NLP?</p>
<p><span class="label label-success">A</span> Neural networks have evolved from simple recurrent neural networks (RNNs) to more advanced models like transformers. RNNs, while powerful, have limitations such as long training times and gradient issues. Transformers, with their attention mechanisms, have surpassed RNNs by enabling parallel processing and capturing long-range dependencies more effectively.</p>
<h6 id="In-A-Nutshell"><a href="#In-A-Nutshell" class="headerlink" title="In A Nutshell"></a>In A Nutshell</h6><p><span class="label label-danger">Q</span> What is the philosophical significance of the shift to statistical NLP?</p>
<p><span class="label label-success">A</span> The shift to statistical NLP highlights the limitations of introspection and suggests that language and thought are not only symbolic but also deeply quantitative and probabilistic. This perspective has driven the integration of formal logical approaches with statistical methods to achieve deeper understanding and more intelligent behavior in language comprehension and dialogue systems.</p>
<h4 id="References"><a href="#References" class="headerlink" title="References"></a>References</h4><p><span class="label label-danger">Q</span> Where can I find the resources to understand these concepts?</p>
<p><span class="label label-success">A</span> Here are some key references:</p>
<ul>
  <li>Rescorla, Michael. “The Computational Theory of Mind.” The Stanford Encyclopedia of Philosophy (Fall 2020 Edition), edited by Edward N. Zalta.</li>
  <li>Rumelhart, D. E., McClelland, J. L., & the PDP Research Group. (1986). Parallel Distributed Processing: Explorations in the Microstructure of Cognition.</li>
  <li>Clark, A. (1993). Connectionism and Cognitive Architecture: A Critical Analysis.</li>
  <li>Bechtel, W., & Graham, G. (Eds.). (1998). Connectionism and Cognitive Science.</li>
  <li>Horgan, T., & Tienson, J. (1996). Foundations of Connectionism: A Reassessment.</li>
  <li>Clark, A. (2001). Mindware: An Introduction to the Philosophy of Cognitive Science.</li>
</ul>

<p>By structuring the article in this Q&amp;A format, it becomes easier to understand the key points and the relationships between different concepts in contemporary NLP.</p>
]]></content>
      <categories>
        <category>NLP Related</category>
      </categories>
      <tags>
        <tag>nlp-theories</tag>
      </tags>
  </entry>
  <entry>
    <title>Measuring Subjectivity</title>
    <url>/nlp-docs/2024/11/23/measuring-subjectivity/</url>
    <content><![CDATA[<h3 id="Understanding-VAE-through-a-different-angle"><a href="#Understanding-VAE-through-a-different-angle" class="headerlink" title="Understanding VAE through a different angle"></a>Understanding VAE through a different angle</h3><p>In a different blog, we have briefly introduced the mechanism behind the VAE algorithm, where it’s essentially taking complex input as numeric values, find a lower-dimensional, structured, and meaningful representation of the input data, and return output that facilitates generative modeling and reconstruction. </p>
]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>math</tag>
        <tag>stochastic</tag>
      </tags>
  </entry>
  <entry>
    <title>Mutual Information</title>
    <url>/nlp-docs/2024/08/03/mutual-info/</url>
    <content><![CDATA[<h3 id="More-on-Mutual-Information"><a href="#More-on-Mutual-Information" class="headerlink" title="More on Mutual Information"></a>More on Mutual Information</h3><p>Below is the code for WAPMI or the Weighted Average Point-wise Mutual Information. And this code measures the distance between two probabilities distributions.</p>
<p>It is a method used in computational linguistics to measure the strength of association between words in a given context, typically in the analysis of text data.</p>
<p>Imagine you have a box of different colored marbles, and you want to know which colors tend to appear together. WAPMI helps you figure out how often certain words (or colors) appear together more often than by random chance. It’s like a smart way to understand word relationships in sentences!</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_pmi</span>(<span class="params">joint_prob, marginal_prob1, marginal_prob2</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculate the pointwise mutual information (PMI) between two words.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param joint_prob: The joint probability of the two words</span></span><br><span class="line"><span class="string">    :param marginal_prob1: The marginal probability of the first word</span></span><br><span class="line"><span class="string">    :param marginal_prob2: The marginal probability of the second word</span></span><br><span class="line"><span class="string">    :return: The PMI score</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> joint_prob == <span class="number">0</span> <span class="keyword">or</span> marginal_prob1 == <span class="number">0</span> <span class="keyword">or</span> marginal_prob2 == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>  <span class="comment"># Avoid division by zero</span></span><br><span class="line">    <span class="keyword">return</span> math.log(joint_prob / (marginal_prob1 * marginal_prob2), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_pmi_corpus_optimized</span>(<span class="params">corpus</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculate the PMI scores for all pairs of words in a corpus.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param corpus: The corpus of text</span></span><br><span class="line"><span class="string">    :return: A dictionary of PMI scores</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    word_counts = collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    cooccurrence_counts = collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    total_sentences = <span class="built_in">len</span>(corpus)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Precompute word counts and co-occurrence counts</span></span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> corpus:</span><br><span class="line">        unique_words = <span class="built_in">set</span>(sentence)  <span class="comment"># Avoid counting duplicates within the same sentence</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> unique_words:</span><br><span class="line">            word_counts[word] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> word1 <span class="keyword">in</span> unique_words:</span><br><span class="line">            <span class="keyword">for</span> word2 <span class="keyword">in</span> unique_words:</span><br><span class="line">                <span class="keyword">if</span> word1 != word2:</span><br><span class="line">                    cooccurrence_counts[(word1, word2)] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate PMI scores</span></span><br><span class="line">    pmi_scores = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> (word1, word2), joint_count <span class="keyword">in</span> cooccurrence_counts.items():</span><br><span class="line">        joint_prob = joint_count / total_sentences</span><br><span class="line">        marginal_prob1 = word_counts[word1] / total_sentences</span><br><span class="line">        marginal_prob2 = word_counts[word2] / total_sentences</span><br><span class="line">        pmi = calculate_pmi(joint_prob, marginal_prob1, marginal_prob2)</span><br><span class="line">        pmi_scores[(word1, word2)] = pmi</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pmi_scores</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage</span></span><br><span class="line">corpus = [</span><br><span class="line">    [<span class="string">&quot;this&quot;</span>, <span class="string">&quot;is&quot;</span>, <span class="string">&quot;a&quot;</span>, <span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>],</span><br><span class="line">    [<span class="string">&quot;bar&quot;</span>, <span class="string">&quot;black&quot;</span>, <span class="string">&quot;sheep&quot;</span>],</span><br><span class="line">    [<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;black&quot;</span>, <span class="string">&quot;sheep&quot;</span>],</span><br><span class="line">    [<span class="string">&quot;sheep&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;black&quot;</span>]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">pmi_scores = calculate_pmi_corpus_optimized(corpus)</span><br><span class="line"><span class="built_in">print</span>(pmi_scores)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>A walkthrough of the code part by part.</p>
<h3 id="Imports"><a href="#Imports" class="headerlink" title="Imports"></a><strong>Imports</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> collections</span><br></pre></td></tr></table></figure>

<ul>
<li><strong><code>import math</code></strong>: Imports the <code>math</code> module, which provides mathematical functions such as logarithms.</li>
<li><strong><code>import collections</code></strong>: Imports the <code>collections</code> module, which provides specialized container datatypes, like <code>defaultdict</code>.</li>
</ul>
<h3 id="Function-Definitions"><a href="#Function-Definitions" class="headerlink" title="Function Definitions"></a><strong>Function Definitions</strong></h3><h4 id="1-calculate-pmi-Function"><a href="#1-calculate-pmi-Function" class="headerlink" title="1. calculate_pmi Function"></a><strong>1. <code>calculate_pmi</code> Function</strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_pmi</span>(<span class="params">word1, word2, joint_prob, marginal_prob1, marginal_prob2</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculate the point-wise mutual information (PMI) between two words.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param word1: The first word</span></span><br><span class="line"><span class="string">    :param word2: The second word</span></span><br><span class="line"><span class="string">    :param joint_prob: The joint probability of the two words</span></span><br><span class="line"><span class="string">    :param marginal_prob1: The marginal probability of the first word</span></span><br><span class="line"><span class="string">    :param marginal_prob2: The marginal probability of the second word</span></span><br><span class="line"><span class="string">    :return: The PMI score</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    pmi = math.log(joint_prob / (marginal_prob1 * marginal_prob2), <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> pmi</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Purpose</strong>: Calculates the Pointwise Mutual Information (PMI) score between two words.</li>
<li><strong>Parameters</strong>:<ul>
<li><code>word1</code> and <code>word2</code>: Words for which PMI is calculated.</li>
<li><code>joint_prob</code>: Probability of both words appearing together.</li>
<li><code>marginal_prob1</code>: Probability of <code>word1</code> appearing.</li>
<li><code>marginal_prob2</code>: Probability of <code>word2</code> appearing.</li>
</ul>
</li>
<li><strong><code>pmi</code> Calculation</strong>:<ul>
<li><code>math.log(joint_prob / (marginal_prob1 * marginal_prob2), 2)</code>: Computes the logarithm (base 2) of the ratio of the joint probability to the product of the marginal probabilities.</li>
</ul>
</li>
<li><strong>Returns</strong>: PMI score.</li>
</ul>
<h4 id="2-calculate-joint-prob-Function"><a href="#2-calculate-joint-prob-Function" class="headerlink" title="2. calculate_joint_prob Function"></a><strong>2. <code>calculate_joint_prob</code> Function</strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_joint_prob</span>(<span class="params">word1, word2, corpus</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculate the joint probability of two words in a corpus.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param word1: The first word</span></span><br><span class="line"><span class="string">    :param word2: The second word</span></span><br><span class="line"><span class="string">    :param corpus: The corpus of text</span></span><br><span class="line"><span class="string">    :return: The joint probability</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    joint_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> corpus:</span><br><span class="line">        <span class="keyword">if</span> word1 <span class="keyword">in</span> sentence <span class="keyword">and</span> word2 <span class="keyword">in</span> sentence:</span><br><span class="line">            joint_count += <span class="number">1</span></span><br><span class="line">    joint_prob = joint_count / <span class="built_in">len</span>(corpus)</span><br><span class="line">    <span class="keyword">return</span> joint_prob</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Purpose</strong>: Calculates the joint probability of two words appearing together in the same sentence.</li>
<li><strong>Parameters</strong>:<ul>
<li><code>word1</code> and <code>word2</code>: Words to check.</li>
<li><code>corpus</code>: List of sentences (each sentence is a list of words).</li>
</ul>
</li>
<li><strong><code>joint_count</code></strong>: Counts how many sentences contain both <code>word1</code> and <code>word2</code>.</li>
<li><strong><code>joint_prob</code> Calculation</strong>: Divides <code>joint_count</code> by the total number of sentences to get the joint probability.</li>
<li><strong>Returns</strong>: Joint probability of the two words.</li>
</ul>
<h4 id="3-calculate-marginal-prob-Function"><a href="#3-calculate-marginal-prob-Function" class="headerlink" title="3. calculate_marginal_prob Function"></a><strong>3. <code>calculate_marginal_prob</code> Function</strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_marginal_prob</span>(<span class="params">word, corpus</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculate the marginal probability of a word in a corpus.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param word: The word</span></span><br><span class="line"><span class="string">    :param corpus: The corpus of text</span></span><br><span class="line"><span class="string">    :return: The marginal probability</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    word_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> corpus:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> sentence:</span><br><span class="line">            word_count += <span class="number">1</span></span><br><span class="line">    marginal_prob = word_count / <span class="built_in">len</span>(corpus)</span><br><span class="line">    <span class="keyword">return</span> marginal_prob</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Purpose</strong>: Calculates the marginal probability of a single word.</li>
<li><strong>Parameters</strong>:<ul>
<li><code>word</code>: The word for which probability is calculated.</li>
<li><code>corpus</code>: List of sentences.</li>
</ul>
</li>
<li><strong><code>word_count</code></strong>: Counts how many sentences contain <code>word</code>.</li>
<li><strong><code>marginal_prob</code> Calculation</strong>: Divides <code>word_count</code> by the total number of sentences to get the marginal probability.</li>
<li><strong>Returns</strong>: Marginal probability of the word.</li>
</ul>
<h4 id="4-calculate-pmi-corpus-Function"><a href="#4-calculate-pmi-corpus-Function" class="headerlink" title="4. calculate_pmi_corpus Function"></a><strong>4. <code>calculate_pmi_corpus</code> Function</strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_pmi_corpus_optimized</span>(<span class="params">corpus</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculate the PMI scores for all pairs of words in a corpus.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param corpus: The corpus of text</span></span><br><span class="line"><span class="string">    :return: A dictionary of PMI scores</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    word_counts = collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    cooccurrence_counts = collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    total_sentences = <span class="built_in">len</span>(corpus)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Precompute word counts and co-occurrence counts</span></span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> corpus:</span><br><span class="line">        unique_words = <span class="built_in">set</span>(sentence)  <span class="comment"># Avoid counting duplicates within the same sentence</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> unique_words:</span><br><span class="line">            word_counts[word] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> word1 <span class="keyword">in</span> unique_words:</span><br><span class="line">            <span class="keyword">for</span> word2 <span class="keyword">in</span> unique_words:</span><br><span class="line">                <span class="keyword">if</span> word1 != word2:</span><br><span class="line">                    cooccurrence_counts[(word1, word2)] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate PMI scores</span></span><br><span class="line">    pmi_scores = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> (word1, word2), joint_count <span class="keyword">in</span> cooccurrence_counts.items():</span><br><span class="line">        joint_prob = joint_count / total_sentences</span><br><span class="line">        marginal_prob1 = word_counts[word1] / total_sentences</span><br><span class="line">        marginal_prob2 = word_counts[word2] / total_sentences</span><br><span class="line">        pmi = calculate_pmi(joint_prob, marginal_prob1, marginal_prob2)</span><br><span class="line">        pmi_scores[(word1, word2)] = pmi</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pmi_scores</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Purpose</strong>: Calculates PMI scores for all pairs of words in the corpus.</li>
<li><strong>Parameters</strong>:<ul>
<li><code>corpus</code>: List of sentences.</li>
</ul>
</li>
<li><strong><code>word_counts</code></strong>: A <code>defaultdict</code> to count occurrences of each word.</li>
<li><strong>Count Words</strong>: Iterates over each sentence to count occurrences of each word.</li>
<li><strong>Compute PMI</strong>:<ul>
<li>Iterates over all pairs of words (excluding pairs where <code>word1</code> is the same as <code>word2</code>).</li>
<li>Calculates joint and marginal probabilities, then computes PMI for each pair.</li>
</ul>
</li>
<li><strong>Returns</strong>: A dictionary of PMI scores for all word pairs.</li>
</ul>
<h3 id="Example-Usage"><a href="#Example-Usage" class="headerlink" title="Example Usage"></a><strong>Example Usage</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">corpus = [</span><br><span class="line">    [<span class="string">&quot;this&quot;</span>, <span class="string">&quot;is&quot;</span>, <span class="string">&quot;a&quot;</span>, <span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>],</span><br><span class="line">    [<span class="string">&quot;bar&quot;</span>, <span class="string">&quot;black&quot;</span>, <span class="string">&quot;sheep&quot;</span>],</span><br><span class="line">    [<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;black&quot;</span>, <span class="string">&quot;sheep&quot;</span>],</span><br><span class="line">    [<span class="string">&quot;sheep&quot;</span>, <span class="string">&quot;bar&quot;</span>, <span class="string">&quot;black&quot;</span>]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">pmi_scores = calculate_pmi_corpus(corpus)</span><br><span class="line"><span class="built_in">print</span>(pmi_scores)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Purpose</strong>: Runs the PMI calculations on a sample corpus and prints the PMI scores for all word pairs.</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a><strong>Summary</strong></h3><ul>
<li><strong><code>calculate_pmi</code></strong> computes PMI given probabilities.</li>
<li><strong><code>calculate_joint_prob</code></strong> finds how often two words appear together.</li>
<li><strong><code>calculate_marginal_prob</code></strong> finds how often one word appears.</li>
<li><strong><code>calculate_pmi_corpus</code></strong> calculates PMI for all word pairs in a corpus.</li>
</ul>
<p>This code helps measure how strongly two words are associated compared to what you would expect by chance.</p>
<h3 id="Comparing-Mutural-Informaiton-WAPMI-VAE-and-KL-Divergence"><a href="#Comparing-Mutural-Informaiton-WAPMI-VAE-and-KL-Divergence" class="headerlink" title="Comparing Mutural Informaiton, WAPMI, VAE, and KL Divergence."></a>Comparing Mutural Informaiton, WAPMI, VAE, and KL Divergence.</h3><p>Let’s break down Wappmi, mutual information, and how they relate to Variational Autoencoders (VAEs) and KL divergence in simple terms, like you’re five.</p>
<h3 id="Mutual-Information"><a href="#Mutual-Information" class="headerlink" title="Mutual Information"></a>Mutual Information</h3><p>Imagine you have two sets of toys, and you want to know how much one set tells you about the other. Mutual information is a way to measure how much knowing about one set of toys helps you predict what’s in the other set. If you always find a red truck when you find a blue car, that’s high mutual information.</p>
<h3 id="Wappmi-Weighted-Average-Prediction-Pointwise-Mutual-Information"><a href="#Wappmi-Weighted-Average-Prediction-Pointwise-Mutual-Information" class="headerlink" title="Wappmi (Weighted Average Prediction Pointwise Mutual Information)"></a>Wappmi (Weighted Average Prediction Pointwise Mutual Information)</h3><p>Now, Wappmi takes this idea of mutual information and looks at words in sentences. It asks, “How often do these words appear together, and is it more than just by chance?” It’s like seeing if certain toys always end up next to each other more than they would randomly.</p>
<h3 id="Variational-Autoencoders-VAEs-and-KL-Divergence"><a href="#Variational-Autoencoders-VAEs-and-KL-Divergence" class="headerlink" title="Variational Autoencoders (VAEs) and KL Divergence"></a>Variational Autoencoders (VAEs) and KL Divergence</h3><p>Imagine you have a machine that tries to guess which toys you might pull out of a box based on previous toys. VAEs are like that machine—they learn patterns to predict what comes next.</p>
<p>The KL Divergence (Kullback-Leibler Divergence) is a way for the machine to measure how different its guesses (predictions) are from what actually happens. It helps the machine get better by adjusting its guesses to be more like what it observes.</p>
<h3 id="How-They-Relate"><a href="#How-They-Relate" class="headerlink" title="How They Relate"></a>How They Relate</h3><ul>
<li><strong>Mutual Information:</strong> Helps understand how related different pieces of data are, like words in a sentence.</li>
<li><strong>Wappmi:</strong> Uses the idea of mutual information to find strong word pairings in text.</li>
<li><strong>VAE:</strong> Tries to model data (like sentences) to understand it better.</li>
<li><strong>KL Divergence:</strong> Helps the VAE improve its understanding by comparing its guesses to reality and adjusting accordingly.</li>
</ul>
<h3 id="Example-Code-Walkthrough"><a href="#Example-Code-Walkthrough" class="headerlink" title="Example Code Walkthrough"></a>Example Code Walkthrough</h3><p>Let’s imagine you have a simple code where you’re trying to guess if two words often appear together:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_stats</span>(<span class="params">vocab</span>):</span><br><span class="line">    pairs = collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    <span class="keyword">for</span> word, freq <span class="keyword">in</span> vocab.items():</span><br><span class="line">        symbols = word.split()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(symbols) - <span class="number">1</span>):</span><br><span class="line">            pairs[symbols[i], symbols[i + <span class="number">1</span>]] += freq</span><br><span class="line">    <span class="keyword">return</span> pairs</span><br><span class="line"></span><br><span class="line">vocab = &#123;<span class="string">&#x27;new&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;news&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;newer&#x27;</span>: <span class="number">3</span>&#125;</span><br><span class="line">pairs = get_stats(vocab)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pairs)</span><br></pre></td></tr></table></figure>

<p>This code checks how often pairs of words (or symbols) appear together. If “new” and “news” show up together a lot, the program will tell you. This is similar to how Wappmi works.</p>
<p>In a VAE, you might use something like KL divergence to measure how far off your model’s guesses are from reality, then adjust it to improve. The model might then get better at understanding the relationships between words (like mutual information).</p>
<p>This approach helps in building smarter models that can understand and predict data more accurately.</p>
<h3 id="Simple-code-demonstration-of-each-one-of-them"><a href="#Simple-code-demonstration-of-each-one-of-them" class="headerlink" title="Simple code demonstration of each one of them"></a>Simple code demonstration of each one of them</h3><h3 id="1-Mutual-Information"><a href="#1-Mutual-Information" class="headerlink" title="1. Mutual Information"></a>1. <strong>Mutual Information</strong></h3><p><strong>Concept</strong>:<br>Mutual Information (MI) measures how much knowing one random variable reduces uncertainty about another. It quantifies the “shared information” between two variables.</p>
<p><strong>Code Example</strong>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mutual_info_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example data</span></span><br><span class="line">X = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">Y = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate mutual information</span></span><br><span class="line">mi = mutual_info_score(X, Y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Mutual Information: <span class="subst">&#123;mi&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>Explanation</strong>:<br>In this example, <code>mutual_info_score</code> from <code>sklearn</code> calculates the MI between two lists <code>X</code> and <code>Y</code>. MI quantifies how much knowing <code>X</code> helps predict <code>Y</code>.</p>
<h3 id="2-WAPPMI-Weighted-Average-Pointwise-Mutual-Information"><a href="#2-WAPPMI-Weighted-Average-Pointwise-Mutual-Information" class="headerlink" title="2. WAPPMI (Weighted Average Pointwise Mutual Information)"></a>2. <strong>WAPPMI (Weighted Average Pointwise Mutual Information)</strong></h3><p><strong>Concept</strong>:<br>WAPPMI is used in NLP to find out how often words co-occur in a text corpus beyond what would be expected by chance. It gives more weight to frequently co-occurring pairs.</p>
<p><strong>Code Example</strong>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pmi</span>(<span class="params">x, y, corpus</span>):</span><br><span class="line">    px = corpus.count(x) / <span class="built_in">len</span>(corpus)</span><br><span class="line">    py = corpus.count(y) / <span class="built_in">len</span>(corpus)</span><br><span class="line">    pxy = corpus.count(x + <span class="string">&#x27; &#x27;</span> + y) / <span class="built_in">len</span>(corpus)</span><br><span class="line">    <span class="keyword">return</span> math.log(pxy / (px * py), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">corpus = <span class="string">&quot;this is a simple corpus with some simple words in this simple text&quot;</span></span><br><span class="line">pairs = collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example calculation</span></span><br><span class="line">words = corpus.split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(words) - <span class="number">1</span>):</span><br><span class="line">    pairs[(words[i], words[i + <span class="number">1</span>])] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pair, freq <span class="keyword">in</span> pairs.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;PMI(<span class="subst">&#123;pair&#125;</span>): <span class="subst">&#123;pmi(pair[<span class="number">0</span>], pair[<span class="number">1</span>], corpus)&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>Explanation</strong>:<br>The PMI function calculates the pointwise mutual information between word pairs in the <code>corpus</code>. WAPPMI extends this by weighting these values.</p>
<h3 id="3-Variational-Autoencoder-VAE"><a href="#3-Variational-Autoencoder-VAE" class="headerlink" title="3. Variational Autoencoder (VAE)"></a>3. <strong>Variational Autoencoder (VAE)</strong></h3><p><strong>Concept</strong>:<br>VAEs are used to generate data that’s similar to a given dataset. They work by learning a probabilistic model of the data and then sampling from it.</p>
<p><strong>Code Example</strong>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VAE</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, z_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(VAE, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.encoder = nn.Sequential(</span><br><span class="line">            nn.Linear(input_dim, hidden_dim),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_dim, z_dim * <span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.decoder = nn.Sequential(</span><br><span class="line">            nn.Linear(z_dim, hidden_dim),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_dim, input_dim),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        mu_logvar = <span class="variable language_">self</span>.encoder(x)</span><br><span class="line">        mu, logvar = mu_logvar.chunk(<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        std = torch.exp(<span class="number">0.5</span> * logvar)</span><br><span class="line">        z = mu + std * torch.randn_like(std)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.decoder(z), mu, logvar</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate and run the model</span></span><br><span class="line">vae = VAE(input_dim=<span class="number">784</span>, hidden_dim=<span class="number">400</span>, z_dim=<span class="number">20</span>)</span><br><span class="line">sample_input = torch.randn((<span class="number">64</span>, <span class="number">784</span>))</span><br><span class="line">output, mu, logvar = vae(sample_input)</span><br></pre></td></tr></table></figure>

<p><strong>Explanation</strong>:<br>The VAE class in this example defines an encoder and decoder. The encoder outputs a mean (<code>mu</code>) and log-variance (<code>logvar</code>) for a latent variable <code>z</code>. The decoder reconstructs the input data from <code>z</code>. The KL divergence between the latent distribution and a normal distribution helps regularize the model.</p>
<h3 id="4-KL-Divergence"><a href="#4-KL-Divergence" class="headerlink" title="4. KL Divergence"></a>4. <strong>KL Divergence</strong></h3><p><strong>Concept</strong>:<br>KL Divergence measures how one probability distribution diverges from a second, expected probability distribution. It’s used in VAEs to ensure that the latent variables follow a desired distribution (usually a Gaussian).</p>
<p><strong>Code Example</strong>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># KL Divergence between the prior (standard normal) and the approximate posterior (q(z|x))</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kl_divergence</span>(<span class="params">mu, logvar</span>):</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">0.5</span> * torch.<span class="built_in">sum</span>(<span class="number">1</span> + logvar - mu.<span class="built_in">pow</span>(<span class="number">2</span>) - logvar.exp())</span><br><span class="line"></span><br><span class="line">mu = torch.zeros(<span class="number">64</span>, <span class="number">20</span>)</span><br><span class="line">logvar = torch.zeros(<span class="number">64</span>, <span class="number">20</span>)</span><br><span class="line">kl = kl_divergence(mu, logvar)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;KL Divergence: <span class="subst">&#123;kl&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>Explanation</strong>:<br>This code calculates the KL Divergence for a batch of latent variables with <code>mu</code> and <code>logvar</code> as parameters. It shows how much the approximate posterior (the learned distribution) diverges from the prior (standard normal distribution).</p>
<h3 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison:"></a><strong>Comparison</strong>:</h3><ul>
<li><strong>Mutual Information</strong> tells us how much knowing one variable helps us know another.</li>
<li><strong>WAPPMI</strong> applies this idea to words in text, showing how often they appear together.</li>
<li><strong>VAEs</strong> are generative models that learn to create data similar to a training set. They use <strong>KL Divergence</strong> to ensure the generated data follows a specific distribution.</li>
</ul>
<p><strong>Overall</strong>, these concepts are connected through their use in understanding and modeling the relationships within data, whether through measuring information (MI, WAPPMI) or generating and adjusting data distributions (VAEs, KL Divergence).</p>
]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>nlp-theories</tag>
      </tags>
  </entry>
  <entry>
    <title>Philosophy of Mind</title>
    <url>/nlp-docs/2024/08/13/philo-o-mind/</url>
    <content><![CDATA[<h3 id="Cognitive-Science-and-The-Philosophy-of-Mind"><a href="#Cognitive-Science-and-The-Philosophy-of-Mind" class="headerlink" title="Cognitive Science and The Philosophy of Mind"></a>Cognitive Science and The Philosophy of Mind</h3><p><span class="label label-danger">Q</span> What is the focus of this blog?</span></p>
<p><span class="label label-success">A</span> This blog will summarize articles, papers, and materials I have gone through that touch on the subject of Philosophy of Mind and how its presence lays important foundation for the development of general artificial intelligence.</p>
<p>The blog covers the following topics:</p>
<ul>
  <li>What Constitutes The Philosophy of Mind</li>
  <li>The Implications of Human Beings As Conscious Automata</li>
  <li>Consciousness As The Fundamental Property of Nature</li>
  <li>Consciousness As A Weak, Strong, or Normal Emergence</li>
  <li>The Primal Instincts vs. The Unknown</li>
  <li>Theories That Address The Mind-Body Problem</li>
  <li>Computationalism and The Computational Theory of Mind</li>
  <li>A Turing Style Computational System</li>
  <li>The Computational vs The Representational Theory of Mind</li>
  <li>Computationalism vs Functionalism</li>
  <li>The Emergence of The Representational Theory of Mind</li>
  <li>What Are Syntactic Underpinnings?</li>
  <li>Tying Everything Together and Connecting The Dots</li>
  <li>In A Nutshell</li>
</ul>

<p><span class="label label-danger">Q</span> What are “easy” and “hard” problems of consciousness?</span></p>
<p><span class="label label-success">A</span> The <code>easy problems</code> involve understanding mechanisms of perception, attention, and behavior. The <code>hard problem</code> concerns subjective experience or <code>qualia</code>, which are deeply subjective and cannot be directly observed or measured.</p>
<p><span class="label label-danger">Q</span> What is fundamental property dualism?</span></p>
<p><span class="label label-success">A</span> Fundamental property dualism regards conscious mental properties as basic constituents of reality, on a par with fundamental physical properties. This view is also referred to as <code>panpsychism</code>.</p>
<p><span class="label label-danger">Q</span> What are the hypotheses over the emergence and origin of consciousness?</span></p>
<p><span class="label label-success">A</span> The hypotheses include <code>strong emergence</code>, <code>weak emergence</code>, and <code>normal emergence</code>. Each hypothesis offers a different perspective on how consciousness arises from physical processes:</p>
<ul>
  <li><b>Strong Emergence:</b> Higher-level properties that are fundamentally new and cannot be reduced to lower-level explanations. For example, consciousness itself might be considered strongly emergent, involving subjective experiences that cannot be directly deduced from neural activity alone.</li>
  <li><b>Weak Emergence:</b> Higher-level properties that are unexpected but fully explainable by lower-level processes. For example, the behavior of a flock of birds can be explained by simple rules followed by individual birds, leading to complex patterns.</li>
  <li><b>Normal Emergence:</b> Properties that arise predictably from underlying processes. For example, the temperature of a gas results from the average kinetic energy of its molecules, and this relationship is well-understood and predictable.</li>
</ul>

<p><span class="label label-danger">Q</span> What is the <code>Primal Instincts vs. The Unknown</code> theory?</span></p>
<p><span class="label label-success">A</span> This theory suggests that humans could perform tasks as automata without being aware of it, citing examples such as driving while talking and fight-or-flight responses.</p>
<p><span class="label label-danger">Q</span> What is the significance of consciousness according to Thomas Henry Huxley?</span></p>
<p><span class="label label-success">A</span> Huxley believed that sensations and feelings are mere byproducts of the brain’s mechanics, and do not cause any behavior.</p>
<p><span class="label label-danger">Q</span> What is the <code>&quot;Nomological dangler&quot;</code> according to J.J.C. Smart?</span></p>
<p><span class="label label-success">A</span> Smart argued that seeing consciousness as a purely physical process eliminates the need to explain the grey area of brain processes in a more scientific and established system.</p>
<p><span class="label label-danger">Q</span> What are the theories that address the mind-body problem?</span></p>
<p><span class="label label-success">A</span> Theories include Type vs. Token Identity Theory, Eliminative Materialism, Functionalism, Neutral Monism, and Mind-Body Dualism. These theories offer different perspectives on the relationship between consciousness and the physical world:</p>
<ul>
  <li><b>Type vs. Token Identity Theory:</b> Proposes that mental states are identical to specific physical states or processes in the brain. Type identity theory suggests each mental state type corresponds to a specific physical state type, while token identity theory allows for different physical states across different instances.</li>
  <li><b>Eliminative Materialism:</b> Suggests that current folk psychology and common-sense understandings of mental states, including consciousness, are fundamentally flawed and may be eliminated or revised in light of future scientific understanding.</li>
  <li><b>Functionalism:</b> Defines consciousness in terms of functional roles within a system, emphasizing the causal relations between inputs, outputs, and other mental states. Consciousness arises from the functional organization of the brain.</li>
  <li><b>Neutral Monism:</b> Proposes that consciousness and physical phenomena are different manifestations of a neutral substance or property underlying reality. Consciousness is neither purely mental nor purely physical but emerges from a more fundamental neutral substrate.</li>
  <li><b>Mind-Body Dualism:</b> Posits that consciousness is a non-physical or immaterial aspect of reality. It suggests that consciousness exists independently of physical processes and may have properties that cannot be fully explained in terms of material phenomena.</li>
</ul>

<p><span class="label label-danger">Q</span> What is Computationalism?</span></p>
<p><span class="label label-success">A</span> Computationalism holds that the mind is a computational system similar to a Turing machine, and core mental processes are computations similar to those executed by a Turing machine.</p>
<p><span class="label label-danger">Q</span> What is a <code>Turing-style computational system</code>?</span></p>
<p><span class="label label-success">A</span> A Turing-style computational system includes memory locations, a central processor, and a machine table that determines the processor’s actions based on its current state and the symbol it is accessing.</p>
<p><span class="label label-danger">Q</span> How does the Computational Theory of Mind (CTM) compare with the Representational Theory of Mind (RTM)?</span></p>
<p><span class="label label-success">A</span> CTM focuses on computational processes, while RTM emphasizes mental representations and their connections to the external world. RTM addresses limitations of CTM by incorporating qualitative aspects of consciousness and flexible cognitive processing.</p>
<p><span class="label label-danger">Q</span> What are <code>productivity</code> and <code>systematicity</code> in CTM and RTM?</span></p>
<p><span class="label label-success">A1</span>
<b>CTM:</b>
  <ul>
    <li><b>Productivity:</b> CTM explains the productivity of thoughts by assuming that the mind, as a computational system, can generate an infinite number of thoughts from a finite set of symbols and rules.</li>
    <li><b>Systematicity:</b> CTM assumes systematicity by subscribing to the structural organization of thoughts and the systematic rules of inference that govern them.</li>
  </ul>
  <p><span class="label label-success">A2</span>
  <b>RTM:</b>
  <ul>
    <li><b>Productivity:</b> RTM posits that a finite set of symbols in natural language can entertain an infinite number of logical propositions using a finite set of concepts and ideas.</li>
    <li><b>Systematicity:</b> RTM highlights the inherent systematic relationships between basic cognitive constituents, facilitating coherent and structured thought processes.</li>
  </ul>


<p><span class="label label-danger">Q</span> What are the limitations of CTM?</span></p>
<p><span class="label label-success">A</span> Limitations include the <code>Symbol Grounding Problem</code>, difficulty in explaining <code>qualia</code> and <code>consciousness</code>, and rigid rule-based processing that may not capture the flexible nature of human cognition.<br><span class="label label-danger">Q</span> What is <code>Connectionism</code>?</span></p>
<p><span class="label label-success">A</span> Connectionism is an approach within cognitive science that emphasizes distributed processing and learning from experience, using interconnected units similar to neurons in the brain.</p></p>
<p><span class="label label-danger">Q</span> What is the significance of hybrid models in AI?</span></p>
<p><span class="label label-success">A</span> Hybrid models integrate connectionist ideas with representational theories, combining symbolic manipulation capabilities with the learning and adaptability features of connectionism.</p></p>
<p><span class="label label-danger">Q</span> What are <code>syntactic underpinnings</code>?</span></p>
<p><span class="label label-success">A</span> Syntactic underpinnings refer to the foundational principles and structures that dictate the formation of sentences and phrases in a language, including rules for word order, phrase structure, and grammatical categories.</p></p>
<p><span class="label label-danger">Q</span> What strategies can address <code>syntactic underpinnings</code>?</span></p>
<p><span class="label label-success">A</span> Strategies include using grammar formalisms, developing parsing techniques, building rule-based systems, leveraging linguistic resources, and employing machine and deep learning approaches to learn syntactic patterns.</p></p>
<p><span class="label label-danger">Q</span> How does <code>Connectionism</code> address the limitations of <code>CTM</code>?</span></p>
<p><span class="label label-success">A</span> Connectionism offers a dynamic, continuous representation of cognitive processes through interconnected units, addressing the rigidity and symbolic limitations of CTM by using distributed representations and learning from experience.</p></p>
<p><span class="label label-danger">Q</span> What is the main takeaway from this blog?</span></p>
<p><span class="label label-success">A</span> The blog explores the <code>Computational Theory of Mind (CTM)</code> and its implications, addressing various theories on consciousness, the mind-body problem, and cognitive processes. It highlights the limitations of CTM and introduces <code>Connectionism</code> and the <code>Representational Theory of Mind (RTM)</code> as alternative approaches.</p></p>
<p><span class="label label-danger">Q</span> Where could I find the resources that help me understand these concepts?</span></p>
<p><span class="label label-success">A</span> Here are some key references:</p></p>
<ul>
  <li>Rescorla, Michael. "The Computational Theory of Mind." The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Fall 2020 Edition.</li> <li>Rumelhart, David E., James L. McClelland, and the PDP Research Group. Parallel Distributed Processing: Explorations in the Microstructure of Cognition, 1986.</li>
  <li.Clark, Andy. Connectionism and Cognitive Architecture: A Critical Analysis, 1993.</li>
  <li>Bechtel, William, and George Graham, editors. Connectionism and Cognitive Science, 1998.</li>
  <li>Horgan, Terence, and John Tienson. Foundations of Connectionism: A Reassessment, 1996.</li>
  <li>Clark, Andy. Mindware: An Introduction to the Philosophy of Cognitive Science, 2001.</li>
</ul>
]]></content>
      <categories>
        <category>Linguistics</category>
      </categories>
      <tags>
        <tag>nlp-theories</tag>
      </tags>
  </entry>
  <entry>
    <title>Intro &amp; Overview</title>
    <url>/nlp-docs/2024/07/11/place-holder/</url>
    <content><![CDATA[<h1 id="Hello-There-Welcome-To-This-Blog"><a href="#Hello-There-Welcome-To-This-Blog" class="headerlink" title="Hello There! Welcome To This Blog."></a><span id="title-intro">Hello There! Welcome To This Blog.</span></h1><p>I’m Shiyi. I’m deeply passionate about the intricate dance between data and innovation. With a fervent zeal for leveraging technology to extract insights and create a meaningful impact, I’ve embarked on a journey that spans the realms of Data Science, research, and creative expression.</p>
<p><span class="label label-danger">Q</span> What drives my work in Data Science and Machine Learning?</span></p>
<p><span class="label label-success">A</span> At the heart of my endeavors lies a profound appreciation for machine learning, deep learning, and Natural Language Processing. As an advocate for data-driven decision-making, I thrive on unraveling the complexities of algorithms and patterns, harnessing their power to transform raw data into actionable intelligence. From predictive modeling in finance to image recognition tasks using deep learning architectures, I relish the challenge of pushing the boundaries of what’s possible with data.</p>
<p><span class="label label-danger">Q</span> What is my expertise in Natural Language Processing?</span></p>
<p><span class="label label-success">A</span> My expertise extends to the captivating domain of Natural Language Processing. In an era inundated with information, I’m committed to empowering systems to understand, analyze, and generate insights from vast textual data. Whether it’s sentiment analysis to decipher the mood of social media conversations or language translation to bridge communication gaps, I’m fascinated by the potential of NLP to revolutionize how we interact with language.</p>
<p><span class="label label-danger">Q</span> How do I combine creativity with my data-driven work?</span></p>
<p><span class="label label-success">A</span> My passion for crafting extends beyond the digital realm to embrace a hands-on approach to creativity. From knitting intricate patterns inspired by my rabbit’s playful nature to sketching designed to stimulate curiosity and exploration, I find immense fulfillment in blending data-driven insights with the artistry of crafting.</p>
<p><span class="label label-danger">Q</span> What is the essence of my journey?</span></p>
<p><span class="label label-success">A</span> In essence, my journey is defined by a relentless pursuit of innovation, fueled by the boundless possibilities that arise at the nexus of data, creativity, and companionship. With each endeavor, I strive to push the boundaries of what’s possible, shaping a future where technology not only empowers but also enriches our lives in meaningful and unexpected ways. To channel such a passion, I created this blog to document the things I find helpful and important in understanding some of the most crucial concepts. I hope in such a format, I can grow with you or someone who is interested in learning these cool things.</p>
<p><span class="label label-danger">Q</span> Is this the only blog? </span></p>
<p><span class="label label-success">A</span> I have also created a separate blog for documenting the gists of NLP. This page will summarize important theories that lay the foundation for the development of AI, speech &amp; language processing, and computational linguistics to provide more context.</p>
<h4></h4>
]]></content>
      <tags>
        <tag>intro</tag>
      </tags>
  </entry>
  <entry>
    <title>Problem Solving</title>
    <url>/nlp-docs/2024/07/17/problem-solving/</url>
    <content><![CDATA[<h3 id="More-on-Logic-And-Problem-Solving"><a href="#More-on-Logic-And-Problem-Solving" class="headerlink" title="More on Logic And Problem Solving"></a>More on Logic And Problem Solving</h3><p>In a different <a href="https://shiyis.github.io/nlpwme/modules/1h-semantics/">blog</a>, I have briefly introduced some of the most important concepts of logic and problem solving, including but not limited to predicate calculus, propositional logic, and lambda calculus.</p>
<p>In this blog, the notes will be more in detail and introduce relevant ideas.</p>
<h4 id="Defining-Entailment-Implicatures-and-Presuppositions"><a href="#Defining-Entailment-Implicatures-and-Presuppositions" class="headerlink" title="Defining Entailment, Implicatures, and Presuppositions"></a>Defining Entailment, Implicatures, and Presuppositions</h4><p><strong>Implicatures</strong>: What’s suggested in an utterance, even though it is not explicitly stated or entailed by the utterance.</p>
<p><strong>Entailment</strong>: Entailment is a relationship between statements where one statement necessarily follows from another. If statement A entails statement B, then if A is true, B must also be true.</p>
<p><strong>Presuppositions</strong>: A presupposition is an assumption that as speaker makes about what the listener already knows or believes to be true. It’s information taken for granted in the utterance.</p>
<h4 id="Differences-Between-The-Above-Three"><a href="#Differences-Between-The-Above-Three" class="headerlink" title="Differences Between The Above Three"></a>Differences Between The Above Three</h4><p>Let’s define implicatures, entailments, and presuppositions and compare their differences in simple terms</p>
<p><em><strong>Nature of Meaning</strong></em>:</p>
<ul>
<li><strong>Implicature</strong>: Implied meaning that relies on context and shared understanding. It is not directly stated but inferred.</li>
<li><strong>Entailment</strong>: Logical meaning that follows necessarily from the truth of another statement. It is a strict logical relationship.</li>
<li><strong>Presupposition</strong>: Assumed background information or beliefs. It is taken for granted by the speaker as known to the listener.</li>
</ul>
<p><em><strong>Dependence on Context</strong></em>:</p>
<ul>
<li><strong>Implicature</strong>: Highly dependent on context. The same statement can imply different things in different situations.</li>
<li><strong>Entailment</strong>: Not dependent on context. If the antecedent is true, the consequent must be true regardless of context.</li>
<li><strong>Presupposition</strong>: Partially dependent on context. It relies on shared knowledge but is less flexible than implicature.</li>
</ul>
<p><em><strong>Truth Conditions</strong></em>:</p>
<ul>
<li><strong>Implicature</strong>: Can be canceled or denied without contradiction. For example, “It’s cold in here” doesn’t necessarily mean the speaker wants the window closed if they follow up with, “But I like it that way.”</li>
<li><strong>Entailment</strong>:<br>  Cannot be canceled without contradiction. If “All cats are animals” is true, saying “No cats are animals” would be a direct contradiction.</li>
<li><strong>Presupposition</strong>: Remains even if the statement is negated. For example, “John’s brother is not tall” still presupposes that John has a brother.</li>
</ul>
<p><em><strong>Example Comparisons</strong></em>:</p>
<ul>
<li><strong>Implicature</strong>:<br>  Statement: “Can you pass the salt?”<br>  Implicature: The speaker is asking you to pass the salt, not questioning your ability to do so.</li>
<li><strong>Entailment</strong>:<br>  Statement: “She is a mother.”<br>  Entailment: She has a child. If “She is a mother” is true, it logically follows that “She has a child” must be true.</li>
<li><strong>Presupposition</strong>:<br>  Statement: “The king of France is bald.”<br>  Presupposition: There is a king of France. This assumption is taken for granted by the speaker.</li>
</ul>
<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p><strong>Implicatures</strong> are implied meanings that depend on context and can be canceled without contradiction.<br><strong>Entailments</strong> are logical consequences that must be true if the initial statement is true, and they cannot be canceled without contradiction.<br><strong>Presuppositions</strong> are background assumptions that remain true even if the statement is negated and depend on shared knowledge between the speaker and listener.<br>By understanding these differences, we can better analyze and interpret the subtleties of communication and language use.</p>
<h4 id="The-Gists-of-Predicate-Calculus-and-Propositional-Logic"><a href="#The-Gists-of-Predicate-Calculus-and-Propositional-Logic" class="headerlink" title="The Gists of Predicate Calculus and Propositional Logic"></a>The Gists of Predicate Calculus and Propositional Logic</h4><h4 id="Basic-Concepts-of-Lambda-Calculus"><a href="#Basic-Concepts-of-Lambda-Calculus" class="headerlink" title="Basic Concepts of Lambda Calculus"></a>Basic Concepts of Lambda Calculus</h4><p>Lambda calculus is a formal system in mathematical logic and computer science for expressing computation based on function abstraction and application. It was introduced by Alonzo Church in the 1930s as part of his work on the foundations of mathematics.</p>
<h4 id="1-Lambda-Abstraction"><a href="#1-Lambda-Abstraction" class="headerlink" title="1. Lambda Abstraction:"></a>1. <strong>Lambda Abstraction</strong>:</h4><ul>
<li><strong>Syntax</strong>: <code>λx. E</code></li>
<li><strong>Explanation</strong>: This denotes an anonymous function with a parameter <code>x</code> and body <code>E</code>. For example, <code>λx. x + 1</code> represents a function that takes an argument <code>x</code> and returns <code>x + 1</code>.</li>
</ul>
<h4 id="2-Application"><a href="#2-Application" class="headerlink" title="2. Application:"></a>2. <strong>Application</strong>:</h4><ul>
<li><strong>Syntax</strong>: <code>(F A)</code></li>
<li><strong>Explanation</strong>: This denotes the application of function <code>F</code> to argument <code>A</code>. For example, <code>(λx. x + 1) 2</code> applies the function <code>λx. x + 1</code> to <code>2</code>, resulting in <code>3</code>.</li>
</ul>
<h4 id="3-Variables"><a href="#3-Variables" class="headerlink" title="3. Variables:"></a>3. <strong>Variables</strong>:</h4><ul>
<li><strong>Syntax</strong>: <code>x</code></li>
<li><strong>Explanation</strong>: Variables are placeholders for values or other expressions. In <code>λx. x</code>, <code>x</code> is a variable.</li>
</ul>
<h4 id="Expressions"><a href="#Expressions" class="headerlink" title="Expressions"></a>Expressions</h4><p>In lambda calculus, expressions are built using variables, lambda abstractions, and applications. These are called lambda expressions or terms. The grammar of lambda expressions is defined as:</p>
<ul>
<li><strong>Variables</strong>: <code>x, y, z, ...</code></li>
<li><strong>Lambda Abstraction</strong>: <code>λx. E</code> where <code>x</code> is a variable and <code>E</code> is a lambda expression.</li>
<li><strong>Application</strong>: <code>(E1 E2)</code> where <code>E1</code> and <code>E2</code> are lambda expressions.</li>
</ul>
<h4 id="Reduction"><a href="#Reduction" class="headerlink" title="Reduction"></a>Reduction</h4><p>Lambda calculus defines computation through the process of <strong>reduction</strong>, which simplifies lambda expressions. There are two main types of reduction:</p>
<ol>
<li><p><strong>Alpha Conversion (α conversion)</strong>:<br> <strong>Explanation</strong>: Renaming the bound variables in a lambda expression. For example, <code>λx. x</code> can be alpha-converted to <code>λy. y</code>.<br> <strong>Purpose</strong>: Avoids name collisions.</p>
</li>
<li><p><strong>Beta Reduction (β reduction)</strong>:<br> <strong>Explanation</strong>: Applying a lambda function to an argument. For example, <code>(λx. x + 1) 2</code> reduces to <code>2 + 1</code> which further reduces to <code>3</code>.<br> <strong>Process</strong>: Replace the bound variable with the argument in the body of the abstraction. <code>(λx. E1) E2</code> reduces to <code>E1[E2/x]</code>, where <code>E1[E2/x]</code> denotes substitution of <code>E2</code> for <code>x</code> in <code>E1</code>.</p>
</li>
</ol>
<h4 id="Example-of-Beta-Reduction"><a href="#Example-of-Beta-Reduction" class="headerlink" title="Example of Beta Reduction"></a>Example of Beta Reduction</h4><p>Consider the expression: <code>(λx. (λy. x + y) 2) 3</code>.</p>
<ol>
<li><p>Apply the outer function <code>(λx. (λy. x + y) 2)</code> to <code>3</code>:<br> <code>((λx. (λy. x + y) 2) 3)</code><br> Substitute <code>3</code> for <code>x</code> in <code>(λy. x + y) 2</code>: <code>(λy. 3 + y) 2</code>.</p>
</li>
<li><p>Apply the inner function <code>(λy. 3 + y)</code> to <code>2</code>:<br> <code>((λy. 3 + y) 2)</code><br> Substitute <code>2</code> for <code>y</code> in <code>3 + y</code>: <code>3 + 2</code>.</p>
</li>
<li><p>Simplify the expression:<br> <code>3 + 2</code> reduces to <code>5</code>.</p>
</li>
</ol>
<h4 id="Significance-in-Computer-Science"><a href="#Significance-in-Computer-Science" class="headerlink" title="Significance in Computer Science"></a>Significance in Computer Science</h4><p>Lambda calculus serves as the foundation for understanding computation and functional programming languages. Key aspects include:</p>
<ul>
<li><strong>Functional Programming</strong>: Languages like Haskell, Lisp, and Scheme are heavily influenced by lambda calculus.</li>
<li><strong>Programming Language Theory</strong>: Lambda calculus provides a framework for studying the properties of functions and recursive definitions.</li>
<li><strong>Type Systems</strong>: Extensions of lambda calculus, such as the simply typed lambda calculus, form the basis for type systems in programming languages.</li>
</ul>
<h4 id="Church-Turing-Alonzo-Church-and-Alan-Turing-Thesis"><a href="#Church-Turing-Alonzo-Church-and-Alan-Turing-Thesis" class="headerlink" title="Church-Turing (Alonzo Church and Alan Turing) Thesis"></a>Church-Turing (Alonzo Church and Alan Turing) Thesis</h4><p>Lambda calculus is also central to the <strong>Church-Turing thesis</strong>, which posits that any computable function can be computed by a Turing machine, and equivalently, can be expressed in lambda calculus. This establishes lambda calculus as a universal model of computation.</p>
<p>In summary, lambda calculus is a powerful mathematical formalism for defining and studying computation. Its simplicity and expressiveness make it a cornerstone of theoretical computer science and a valuable tool for understanding the base of programming languages.</p>
<h4 id="In-A-Nutshell"><a href="#In-A-Nutshell" class="headerlink" title="In A Nutshell"></a>In A Nutshell</h4><p>The contributions of <strong>Alonzo Church</strong> and <strong>Alan Turing</strong>, particularly their work on the <strong>Church-Turing thesis</strong> and the development of <strong>lambda calculus</strong> and <strong>Turing machines</strong>, can be discussed under the broader umbrella of <strong>problem-solving</strong> and <strong>logical reasoning</strong>. Their ideas fit well within the same conceptual framework as <strong>traditional syllogistic logic</strong>, such as <strong>propositional logic</strong> and <strong>predicate logic</strong>, since all of these approaches are aimed at formalizing methods of reasoning and solving problems in structured, logical ways.</p>
]]></content>
      <categories>
        <category>Linguistics</category>
      </categories>
      <tags>
        <tag>semantics</tag>
      </tags>
  </entry>
  <entry>
    <title>Quantifying Beliefs</title>
    <url>/nlp-docs/2024/09/29/quant-belief/</url>
    <content><![CDATA[<h3 id="This-Blog-Will-Go-Through-Some-Fun-Things-About-Modeling-Beliefs-with-Bayesian-Methods"><a href="#This-Blog-Will-Go-Through-Some-Fun-Things-About-Modeling-Beliefs-with-Bayesian-Methods" class="headerlink" title="This Blog Will Go Through Some Fun Things About Modeling Beliefs with Bayesian Methods"></a>This Blog Will Go Through Some Fun Things About Modeling Beliefs with Bayesian Methods</h3><p>The relationship between <strong>Bayesian conditional probability</strong> and theological discussions, particularly the existence or understanding of God, has been a subject of philosophical and theological debate for centuries. I will first explain the <strong>Bayesian conditional probability equation</strong> in a simple way and then explore how it might relate to theological concepts like belief in God.</p>
<h3 id="Bayesian-Conditional-Probability"><a href="#Bayesian-Conditional-Probability" class="headerlink" title="Bayesian Conditional Probability"></a><strong>Bayesian Conditional Probability</strong></h3><p>At its core, <strong>Bayes’ Theorem</strong> helps us <strong>update our beliefs</strong> when we receive new evidence. It tells us how likely something is to be true (the <strong>posterior probability</strong>) given what we already believe (the <strong>prior probability</strong>) and the new evidence we observe.</p>
<p>Bayes’ Theorem is expressed as:</p>
<p>$$<br>P(A | B) &#x3D; \frac{P(B | A) \cdot P(A)}{P(B)}<br>$$</p>
<p>Where:</p>
<ul>
<li>$ P(A | B) $ is the <strong>posterior probability</strong>: the probability of $ A $ being true given that we observe $ B $.</li>
<li>$ P(B | A) $ is the <strong>likelihood</strong>: how likely we would be to observe $ B $ if $ A $ is true.</li>
<li>$ P(A) $ is the <strong>prior probability</strong>: our initial belief about $ A $ before seeing any evidence.</li>
<li>$ P(B) $ is the <strong>marginal probability</strong>: the total probability of observing $ B $, regardless of whether $ A $ is true or not.</li>
</ul>
<p>In essence, <strong>Bayes’ Theorem</strong> helps us <strong>update our beliefs</strong> in the light of new evidence. For example, it is often used in medical diagnostics, where we update the likelihood of a patient having a disease based on new test results.</p>
<h3 id="Bayesian-Reasoning-and-God"><a href="#Bayesian-Reasoning-and-God" class="headerlink" title="Bayesian Reasoning and God"></a><strong>Bayesian Reasoning and God</strong></h3><p>Now, how does this relate to God or theology?</p>
<ol>
<li><strong>Belief in God as a Hypothesis</strong>:</li>
</ol>
<ul>
<li>You can think of <strong>belief in God</strong> as the hypothesis $ A $, and some kind of <strong>evidence</strong> as $ B $. This evidence could be anything that people consider relevant, such as personal experiences, miracles, the existence of the universe, or moral values.</li>
</ul>
<ol start="2">
<li><strong>Prior Probability</strong> $ P(A) $:</li>
</ol>
<ul>
<li>This represents a person’s initial belief about whether God exists before considering the evidence. Different people have different prior probabilities depending on their background, education, culture, and other factors. Some people may have a strong belief in God’s existence (high prior), while others may be more skeptical (low prior).</li>
</ul>
<ol start="3">
<li><strong>Likelihood</strong> $ P(B | A) $:</li>
</ol>
<ul>
<li>This is the probability of observing the evidence $ B $ if God exists. For example, if the hypothesis is that God exists and the evidence is the fine-tuning of the universe, you would ask: how likely is it that this fine-tuning would exist if God exists?</li>
</ul>
<ol start="4">
<li><strong>Posterior Probability</strong> $ P(A | B) $:</li>
</ol>
<ul>
<li>After considering the evidence (e.g., personal experiences, philosophical arguments, scientific observations), Bayes’ Theorem helps us calculate the updated probability (posterior) of the hypothesis (i.e., belief in God). This represents how our belief in the existence of God changes after taking the new evidence into account.</li>
</ul>
<h3 id="Using-Bayes’-Theorem-to-Argue-for-or-Against-God’s-Existence"><a href="#Using-Bayes’-Theorem-to-Argue-for-or-Against-God’s-Existence" class="headerlink" title="Using Bayes’ Theorem to Argue for or Against God’s Existence:"></a><strong>Using Bayes’ Theorem to Argue for or Against God’s Existence</strong>:</h3><p>Bayes’ Theorem has been used in debates both <strong>for</strong> and <strong>against</strong> the existence of God. Here’s how different arguments might be framed using Bayesian reasoning:</p>
<ol>
<li><strong>Theistic Argument (Evidence Supporting God)</strong>:</li>
</ol>
<ul>
<li>A common theistic argument might use the <strong>fine-tuning</strong> of the universe as the evidence $ B $. Proponents argue that the existence of such precise conditions for life is much more likely if God exists (high $ P(B | A) $) than if God does not exist (low $ P(B) $).</li>
<li>If we assign a reasonable prior probability $ P(A) $ to God’s existence, then the posterior probability $ P(A | B) $ might be higher after considering the evidence.</li>
</ul>
<ol start="2">
<li><strong>Atheistic Argument (Evidence Against God)</strong>:</li>
</ol>
<ul>
<li>On the other hand, someone skeptical of the existence of God might point to the <strong>problem of evil</strong> as evidence $ B $. They could argue that the existence of so much suffering and evil in the world is more likely if God does not exist than if He does (i.e., $ P(B | A) $ is low if God exists).</li>
<li>This would reduce the posterior probability $ P(A | B) $, leading to a lower belief in God’s existence after considering the evidence of evil.</li>
</ul>
<h3 id="Bayesian-Belief-and-Faith"><a href="#Bayesian-Belief-and-Faith" class="headerlink" title="Bayesian Belief and Faith:"></a><strong>Bayesian Belief and Faith</strong>:</h3><p>It’s important to note that while <strong>Bayesian reasoning</strong> is a powerful tool for updating beliefs in light of evidence, religious belief often involves elements of <strong>faith</strong> that may not be easily reducible to probabilistic reasoning. Faith can involve trust, personal experiences, and relationships that go beyond mere empirical evidence.</p>
<ul>
<li><strong>Faith</strong> might be seen as an area where prior beliefs are so strong that evidence $ B $ doesn’t significantly shift the posterior probability. For example, for a devout person, negative evidence might have little effect on belief in God because their prior probability $ P(A) $ is so high.</li>
</ul>
<h3 id="Limitations-of-Bayesian-Reasoning-in-Theological-Contexts"><a href="#Limitations-of-Bayesian-Reasoning-in-Theological-Contexts" class="headerlink" title="Limitations of Bayesian Reasoning in Theological Contexts:"></a><strong>Limitations of Bayesian Reasoning in Theological Contexts</strong>:</h3><ol>
<li><strong>Subjectivity of Priors</strong>:</li>
</ol>
<ul>
<li>The choice of the <strong>prior probability</strong> $ P(A) $ (belief in God before evidence) is subjective and varies significantly between individuals. What one person considers a strong prior (e.g., due to cultural or personal reasons) might be weak for another.</li>
</ul>
<ol start="2">
<li><strong>Interpretation of Evidence</strong>:</li>
</ol>
<ul>
<li>Evidence $ B $ can also be interpreted differently. For example, a natural disaster might be seen by some as evidence against God (because of suffering), while others might interpret it as a test of faith or part of a divine plan.</li>
</ul>
<ol start="3">
<li><strong>Non-empirical Nature of Religious Experience</strong>:</li>
</ol>
<ul>
<li>Many aspects of religious belief, such as spiritual experiences or faith in sacred texts, may not be directly quantifiable in the same way that physical or scientific evidence is.</li>
</ul>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion:"></a>Conclusion:</h3><p>Bayesian conditional probability provides a <strong>formal way to update beliefs</strong> based on new evidence, and it can certainly be applied to discussions about the existence of God. However, the Bayesian framework relies heavily on <strong>subjective priors</strong> and how evidence is interpreted, which can vary greatly among individuals. While it can be a useful tool in philosophical debates about God’s existence, belief in God often transcends empirical evidence and enters the realm of <strong>faith</strong>, which might not fit neatly into a probabilistic model.</p>
]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>math</tag>
        <tag>determinism</tag>
      </tags>
  </entry>
  <entry>
    <title>Understanding Qualia</title>
    <url>/nlp-docs/2024/09/02/qulia/</url>
    <content><![CDATA[<h4 id="This-blog-will-try-to-understand-Qualia-comprehensively"><a href="#This-blog-will-try-to-understand-Qualia-comprehensively" class="headerlink" title="This blog will try to understand Qualia comprehensively."></a>This blog will try to understand Qualia comprehensively.</h4><p><strong>Qualia</strong> (pronounced <strong>KWAL-ee-uh</strong>) are the subjective, internal experiences that each individual perceives when interacting with the world. These experiences refer to the way things <em>feel</em> to an individual, rather than their physical or scientific properties. Examples include:</p>
<ul>
<li>The specific redness of a rose as perceived by an individual.</li>
<li>The feeling of pain from a stubbed toe.</li>
<li>The taste of chocolate or the sound of a piano.</li>
</ul>
<p>Qualia are the building blocks of <strong>conscious experience</strong> and are central to discussions in <strong>philosophy of mind</strong>, <strong>consciousness studies</strong>, and <strong>cognitive science</strong>.</p>
<h3 id="Key-Characteristics-of-Qualia"><a href="#Key-Characteristics-of-Qualia" class="headerlink" title="Key Characteristics of Qualia"></a>Key Characteristics of Qualia</h3><ol>
<li><p><strong>Subjectivity</strong>: Qualia are <strong>unique to each person</strong>. While two people might look at the same object, such as a red apple, they might experience the color “red” differently, though both refer to it as “red.” No one can truly know what another person’s subjective experience of “redness” is like.</p>
</li>
<li><p><strong>Inaccessibility</strong>: Qualia cannot be measured or observed by others. You cannot fully explain what chocolate tastes like to someone who has never tasted it. This private aspect of qualia makes them hard to study scientifically.</p>
</li>
<li><p><strong>Qualitative Nature</strong>: Qualia focus on the <em>quality</em> of experience. It is the “what it feels like” to perceive something, rather than objective measurements like wavelength of light or sound frequencies.</p>
</li>
</ol>
<h3 id="Examples-of-Qualia"><a href="#Examples-of-Qualia" class="headerlink" title="Examples of Qualia"></a>Examples of Qualia</h3><ul>
<li><strong>Visual Qualia</strong>: How an individual experiences colors, shapes, and light. For example, the blue of the sky or the green of a forest.</li>
<li><strong>Auditory Qualia</strong>: The perception of sounds, like the particular tone of a violin or the loudness of a car horn.</li>
<li><strong>Tactile Qualia</strong>: The sensation of touch, such as the softness of a blanket or the sharpness of a needle.</li>
<li><strong>Emotional Qualia</strong>: The subjective feeling of emotions, such as joy, sadness, or anger.</li>
</ul>
<h3 id="Philosophical-Importance"><a href="#Philosophical-Importance" class="headerlink" title="Philosophical Importance"></a>Philosophical Importance</h3><ol>
<li><p><strong>The Hard Problem of Consciousness</strong>: Philosopher <strong>David Chalmers</strong> highlighted the difficulty of explaining qualia as part of what he called the “hard problem of consciousness.” While scientists can explain how the brain processes sensory data, they struggle to explain <em>why</em> these processes result in subjective experiences.</p>
</li>
<li><p><strong>The Inverted Spectrum Problem</strong>: Imagine two people both looking at a red apple. One person sees the apple as we traditionally understand red, but the other person’s brain might perceive red as what the first person would call blue. However, both use the word “red” to describe the apple. This thought experiment illustrates the subjectivity and mystery surrounding qualia.</p>
</li>
<li><p><strong>Philosophical Zombies</strong>: This is a hypothetical scenario where beings exist that act exactly like humans but have no conscious experience (i.e., they have no qualia). This idea is used in philosophy to discuss whether consciousness and qualia are necessary for intelligent behavior.</p>
</li>
</ol>
<h3 id="Scientific-Challenges"><a href="#Scientific-Challenges" class="headerlink" title="Scientific Challenges"></a>Scientific Challenges</h3><ol>
<li><p><strong>Measuring Qualia</strong>: One of the biggest challenges in studying qualia is their <strong>subjective nature</strong>. Since they can’t be directly observed or quantified, scientists find it hard to fit them into objective frameworks.</p>
</li>
<li><p><strong>Relationship to the Physical Brain</strong>: Neuroscientists attempt to map brain activity to conscious experiences, but no clear pathway explains how specific brain processes produce qualia. For example, how does the firing of neurons in the visual cortex lead to the experience of seeing blue?</p>
</li>
</ol>
<h3 id="Theories-on-Qualia"><a href="#Theories-on-Qualia" class="headerlink" title="Theories on Qualia"></a>Theories on Qualia</h3><ol>
<li><p><strong>Dualism</strong>: This theory, most famously supported by philosopher <strong>René Descartes</strong>, argues that mind and matter are two distinct substances. According to dualists, qualia exist in the mental realm and cannot be fully explained by physical processes alone.</p>
</li>
<li><p><strong>Physicalism</strong>: In contrast, physicalists believe that everything, including qualia, is ultimately physical in nature. They argue that qualia are simply the result of brain processes, though the exact mechanisms are not yet fully understood.</p>
</li>
<li><p><strong>Panpsychism</strong>: A more radical view, <strong>panpsychism</strong> suggests that all matter, even down to the level of particles, has some form of conscious experience. Under this theory, qualia might be seen as a fundamental property of the universe.</p>
</li>
</ol>
<h3 id="Why-Qualia-Matter"><a href="#Why-Qualia-Matter" class="headerlink" title="Why Qualia Matter"></a>Why Qualia Matter</h3><p>The study of qualia isn’t just an academic exercise; it challenges our understanding of the nature of <strong>consciousness</strong>, <strong>self-awareness</strong>, and <strong>human experience</strong>. The debate over qualia touches on:</p>
<ul>
<li><strong>Artificial Intelligence</strong>: Can machines experience qualia? If not, will they ever truly understand human experiences?</li>
<li><strong>Ethics and Morality</strong>: If we can’t fully understand someone else’s qualia, how can we judge their experiences of pleasure, pain, or emotion?</li>
<li><strong>Neuroscience</strong>: What part of the brain is responsible for creating these subjective experiences?</li>
</ul>
<p>In summary, <strong>qualia</strong> are a crucial concept for understanding how we experience the world, presenting a philosophical and scientific puzzle that remains unsolved. While we can measure physical processes, the <strong>“why”</strong> and <strong>“how”</strong> of personal experience continue to elude a definitive explanation.</p>
]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title>Understanding SGD</title>
    <url>/nlp-docs/2024/11/18/sgd/</url>
    <content><![CDATA[<h3 id="In-this-blog-we-will-comprehensively-go-through-the-concepts-of-stochastic-gradient-descent"><a href="#In-this-blog-we-will-comprehensively-go-through-the-concepts-of-stochastic-gradient-descent" class="headerlink" title="In this blog, we will comprehensively go through the concepts of stochastic gradient descent"></a>In this blog, we will comprehensively go through the concepts of stochastic gradient descent</h3>]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>math</tag>
        <tag>stochastic</tag>
      </tags>
  </entry>
  <entry>
    <title>The GPT Architecture</title>
    <url>/nlp-docs/2024/08/17/transformer/</url>
    <content><![CDATA[<h3 id="Summary-and-breakdown-of-the-code-that-form-the-Generative-Pre-trained-Transformer-architecture-continued"><a href="#Summary-and-breakdown-of-the-code-that-form-the-Generative-Pre-trained-Transformer-architecture-continued" class="headerlink" title="Summary and breakdown of the code that form the Generative Pre-trained Transformer architecture continued"></a>Summary and breakdown of the code that form the Generative Pre-trained Transformer architecture continued</h3><p>Let’s break down the code snippet line by line to understand what each step does in the context of creating positional encodings for a Transformer model using PyTorch.</p>
<h4 id="Code-Snippet"><a href="#Code-Snippet" class="headerlink" title="Code Snippet"></a>Code Snippet</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() *</span><br><span class="line">                                 (-math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">pe = pe.unsqueeze(<span class="number">0</span>).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h4 id="Explanation"><a href="#Explanation" class="headerlink" title="Explanation"></a>Explanation</h4><h6 id="1-div-term-torch-exp-torch-arange-0-d-model-2-float-math-log-10000-0-d-model"><a href="#1-div-term-torch-exp-torch-arange-0-d-model-2-float-math-log-10000-0-d-model" class="headerlink" title="1. div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))"></a>1. <code>div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))</code></h6><ul>
<li><p><strong>Purpose</strong>: Calculate the denominator for the sine and cosine functions in the positional encoding formula.</p>
</li>
<li><p><strong>Breakdown</strong>:</p>
<ul>
<li><code>torch.arange(0, d_model, 2)</code>: Creates a tensor with values starting from <code>0</code> to <code>d_model - 1</code> with a step size of <code>2</code>. This gives us indices like <code>[0, 2, 4, ..., d_model-2]</code>.<ul>
<li>If <code>d_model</code> is <code>512</code>, this tensor will have <code>256</code> values: <code>[0, 2, 4, ..., 510]</code>.</li>
</ul>
</li>
<li><code>.float()</code>: Converts the tensor to a floating-point type.</li>
<li><code>(-math.log(10000.0) / d_model)</code>: Computes a scaling factor for the positional encoding formula. The value <code>10000.0</code> is a hyperparameter that determines the rate of change of the sine and cosine functions.</li>
<li><code>*</code>: Multiplies each value in the tensor by the scaling factor.</li>
<li><code>torch.exp()</code>: Applies the exponential function to each element in the tensor, resulting in the <code>div_term</code> tensor which will be used to scale the positions.</li>
</ul>
</li>
</ul>
<h6 id="2-pe-0-2-torch-sin-position-div-term"><a href="#2-pe-0-2-torch-sin-position-div-term" class="headerlink" title="2. pe[:, 0::2] = torch.sin(position * div_term)"></a>2. <code>pe[:, 0::2] = torch.sin(position * div_term)</code></h6><ul>
<li><p><strong>Purpose</strong>: Compute the sine values for even-indexed dimensions in the positional encoding matrix.</p>
</li>
<li><p><strong>Breakdown</strong>:</p>
<ul>
<li><code>position</code>: A tensor representing the positions of the words in the sequence. This could be something like <code>torch.arange(0, max_len).unsqueeze(1)</code>, where <code>max_len</code> is the maximum sequence length.</li>
<li><code>position * div_term</code>: Element-wise multiplication of the <code>position</code> tensor with the <code>div_term</code> tensor calculated earlier. This scales the positions appropriately.</li>
<li><code>torch.sin()</code>: Applies the sine function to each element in the resulting tensor.</li>
<li><code>pe[:, 0::2]</code>: Selects all rows (<code>:</code>) and every second column starting from <code>0</code> (<code>0::2</code>). This targets the even-indexed dimensions of the positional encoding matrix.</li>
<li><code>=</code>: Assigns the computed sine values to these selected positions in the positional encoding matrix <code>pe</code>.</li>
</ul>
</li>
</ul>
<h6 id="3-pe-1-2-torch-cos-position-div-term"><a href="#3-pe-1-2-torch-cos-position-div-term" class="headerlink" title="3. pe[:, 1::2] = torch.cos(position * div_term)"></a>3. <code>pe[:, 1::2] = torch.cos(position * div_term)</code></h6><ul>
<li><p><strong>Purpose</strong>: Compute the cosine values for odd-indexed dimensions in the positional encoding matrix.</p>
</li>
<li><p><strong>Breakdown</strong>:</p>
<ul>
<li><code>position * div_term</code>: Same as above, scales the positions appropriately.</li>
<li><code>torch.cos()</code>: Applies the cosine function to each element in the resulting tensor.</li>
<li><code>pe[:, 1::2]</code>: Selects all rows (<code>:</code>) and every second column starting from <code>1</code> (<code>1::2</code>). This targets the odd-indexed dimensions of the positional encoding matrix.</li>
<li><code>=</code>: Assigns the computed cosine values to these selected positions in the positional encoding matrix <code>pe</code>.</li>
</ul>
</li>
</ul>
<h6 id="4-pe-pe-unsqueeze-0-transpose-0-1"><a href="#4-pe-pe-unsqueeze-0-transpose-0-1" class="headerlink" title="4. pe = pe.unsqueeze(0).transpose(0, 1)"></a>4. <code>pe = pe.unsqueeze(0).transpose(0, 1)</code></h6><ul>
<li><p><strong>Purpose</strong>: Reshape the positional encoding matrix to match the expected input shape for the Transformer model.</p>
</li>
<li><p><strong>Breakdown</strong>:</p>
<ul>
<li><code>pe.unsqueeze(0)</code>: Adds an extra dimension at the <code>0</code>-th position. If <code>pe</code> originally has shape <code>(max_len, d_model)</code>, it will now have shape <code>(1, max_len, d_model)</code>. This extra dimension is often used to represent the batch size, which is <code>1</code> in this case.</li>
<li><code>transpose(0, 1)</code>: Swaps the <code>0</code>-th and <code>1</code>-st dimensions. After this operation, the shape will be <code>(max_len, 1, d_model)</code>. This step ensures that the positional encoding matrix can be correctly broadcasted and added to the input embeddings in the Transformer model.</li>
</ul>
<p>The division by <code>d_model</code> in the expression <code>(-math.log(10000.0) / d_model)</code> is a critical part of the positional encoding design in the Transformer model. This design ensures that different dimensions of the positional encoding vary at different frequencies. Here’s a more detailed explanation:</p>
<h4 id="Positional-Encoding-in-Transformers"><a href="#Positional-Encoding-in-Transformers" class="headerlink" title="Positional Encoding in Transformers"></a>Positional Encoding in Transformers</h4><p>The idea behind positional encoding is to inject information about the position of each token in the sequence into the token’s embedding. This is necessary because the Transformer model, unlike RNNs or CNNs, does not inherently capture the order of tokens.</p>
<h4 id="Frequency-Scaling"><a href="#Frequency-Scaling" class="headerlink" title="Frequency Scaling"></a>Frequency Scaling</h4><ol>
<li><p><strong>Frequency Spectrum</strong>:</p>
<ul>
<li>By dividing by <code>d_model</code>, we spread the frequencies of the sine and cosine functions across the dimensions of the embedding vector.</li>
<li>The lower dimensions correspond to lower frequencies, and the higher dimensions correspond to higher frequencies. This spread allows the model to capture a wide range of positional dependencies.</li>
</ul>
</li>
<li><p><strong>Mathematical Justification</strong>:</p>
<ul>
<li>The formula for positional encoding in the Transformer is designed such that for a given position $ pos $ and dimension $ i $:<ul>
<li>$ PE_{(pos, 2i)} &#x3D; \sin\left(\frac{pos}{10000^{\frac{2i}{d_{\text{model}}}}}\right) $</li>
<li>$ PE_{(pos, 2i+1)} &#x3D; \cos\left(\frac{pos}{10000^{\frac{2i}{d_{\text{model}}}}}\right) $</li>
</ul>
</li>
<li>The term $\frac{1}{10000^{\frac{2i}{d_{\text{model}}}}}$ ensures that the positions are scaled appropriately across different dimensions.</li>
</ul>
</li>
<li><p><strong>Implementation</strong>:</p>
<ul>
<li>The division by <code>d_model</code> normalizes the range of exponents to ensure they vary smoothly between 0 and 1, creating a geometric progression of frequencies.</li>
</ul>
</li>
</ol>
</li>
</ul>
<h4 id="Detailed-Steps"><a href="#Detailed-Steps" class="headerlink" title="Detailed Steps"></a>Detailed Steps</h4><p>  Let’s rewrite the specific part of the code to understand its purpose:</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() *</span><br><span class="line">                                 (-math.log(<span class="number">10000.0</span>) / d_model))</span><br></pre></td></tr></table></figure>
<p> Let’s break down the specific line of code <code>div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))</code> and explain its purpose in the context of positional encoding in the Transformer model.</p>
<h4 id="Purpose-of-the-Code"><a href="#Purpose-of-the-Code" class="headerlink" title="Purpose of the Code"></a>Purpose of the Code</h4><p>This line of code is part of the positional encoding generation process in the Transformer model, as described in the paper “Attention is All You Need”. The positional encodings allow the model to utilize the order of the sequence since the Transformer itself is position-agnostic.</p>
<h4 id="Breaking-Down-the-Code"><a href="#Breaking-Down-the-Code" class="headerlink" title="Breaking Down the Code"></a>Breaking Down the Code</h4><h6 id="1-torch-arange-0-d-model-2"><a href="#1-torch-arange-0-d-model-2" class="headerlink" title="1. torch.arange(0, d_model, 2)"></a>1. <code>torch.arange(0, d_model, 2)</code></h6><ul>
<li><strong>Purpose</strong>: Creates a sequence of even integers from 0 to <code>d_model - 2</code>.</li>
<li><strong>Example</strong>: If <code>d_model</code> is 512, <code>torch.arange(0, d_model, 2)</code> generates a tensor containing <code>[0, 2, 4, ..., 510]</code>.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">indices = torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Output</strong>: A tensor of shape <code>(d_model/2,)</code> containing even integers up to <code>d_model - 2</code>.</li>
</ul>
<h6 id="2-float"><a href="#2-float" class="headerlink" title="2. .float()"></a>2. <code>.float()</code></h6><ul>
<li><strong>Purpose</strong>: Converts the integer tensor to a tensor of floats. This is necessary because we will perform mathematical operations that require floating-point precision.</li>
<li><strong>Example</strong>: Continuing from the previous step, <code>.float()</code> converts the integer tensor to floating-point numbers.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">indices = indices.<span class="built_in">float</span>()</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Output</strong>: A tensor of shape <code>(d_model/2,)</code> containing floating-point numbers <code>[0.0, 2.0, 4.0, ..., 510.0]</code>.</li>
</ul>
<h6 id="3-math-log-10000-0-d-model"><a href="#3-math-log-10000-0-d-model" class="headerlink" title="3. (-math.log(10000.0) / d_model)"></a>3. <code>(-math.log(10000.0) / d_model)</code></h6><ul>
<li><strong>Purpose</strong>: Computes a scaling factor for the positional encodings. The value <code>-math.log(10000.0) / d_model</code> ensures the positional encodings have values that decay exponentially.</li>
<li><strong>Value</strong>: If <code>d_model</code> is 512, this term calculates to <code>-math.log(10000.0) / 512 ≈ -0.02302585</code>.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scale_factor = -math.log(<span class="number">10000.0</span>) / d_model</span><br></pre></td></tr></table></figure>

<h6 id="4-scale-factor"><a href="#4-scale-factor" class="headerlink" title="4. * scale_factor"></a>4. <code>* scale_factor</code></h6><ul>
<li><strong>Purpose</strong>: Multiplies each element in the tensor of indices by the scale factor. This operation scales the indices to a range suitable for the exponential function, ensuring the positional encodings vary smoothly.</li>
<li><strong>Example</strong>: Continuing from the previous steps, <code>indices * scale_factor</code> scales each index.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scaled_indices = indices * scale_factor</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Output</strong>: A tensor of shape <code>(d_model/2,)</code> with scaled values.</li>
</ul>
<h6 id="5-torch-exp-scaled-indices"><a href="#5-torch-exp-scaled-indices" class="headerlink" title="5. torch.exp(scaled_indices)"></a>5. <code>torch.exp(scaled_indices)</code></h6><ul>
<li><strong>Purpose</strong>: Applies the exponential function to each element in the scaled tensor. The exponential function is used to create a set of frequencies for the positional encodings.</li>
<li><strong>Example</strong>: Applying the exponential function to the scaled indices.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">div_term = torch.exp(scaled_indices)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Output</strong>: A tensor of shape <code>(d_model/2,)</code> containing the calculated frequencies for the positional encodings.</li>
</ul>
<h4 id="Final-Output"><a href="#Final-Output" class="headerlink" title="Final Output"></a>Final Output</h4><p>The variable <code>div_term</code> now contains a series of exponentially scaled values. These values are used to create the positional encodings, which alternate between sine and cosine functions at different frequencies.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">d_model = <span class="number">512</span>  <span class="comment"># Example value</span></span><br><span class="line">indices = torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>()</span><br><span class="line">scale_factor = -math.log(<span class="number">10000.0</span>) / d_model</span><br><span class="line">scaled_indices = indices * scale_factor</span><br><span class="line">div_term = torch.exp(scaled_indices)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(div_term)</span><br></pre></td></tr></table></figure>

<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><ul>
<li><strong><code>torch.arange(0, d_model, 2).float()</code></strong>: Creates a tensor of even indices from 0 to <code>d_model - 2</code> and converts them to floats.</li>
<li><strong><code>(-math.log(10000.0) / d_model)</code></strong>: Computes a scaling factor.</li>
<li><strong><code>* scale_factor</code></strong>: Scales the indices by the computed factor.</li>
<li><strong><code>torch.exp(scaled_indices)</code></strong>: Applies the exponential function to get the final <code>div_term</code>.</li>
</ul>
<h4 id="Purpose-in-Positional-Encoding"><a href="#Purpose-in-Positional-Encoding" class="headerlink" title="Purpose in Positional Encoding"></a>Purpose in Positional Encoding</h4><p>The <code>div_term</code> tensor represents the denominators for the positional encodings’ sine and cosine functions. These frequencies ensure that different positions in the input sequence have unique encodings, allowing the Transformer model to infer the position of each token. The overall goal is to introduce a form of positional information that helps the model understand the order of the sequence.</p>
<h4 id="Intuitive-Understanding"><a href="#Intuitive-Understanding" class="headerlink" title="Intuitive Understanding"></a>Intuitive Understanding</h4><ul>
<li><p><strong>Varying Frequencies</strong>:</p>
<ul>
<li>Lower dimensions of the embedding vector (e.g., dimensions 0, 2, 4) will vary more slowly (lower frequency).</li>
<li>Higher dimensions (e.g., dimensions 508, 510) will vary more quickly (higher frequency).</li>
</ul>
</li>
<li><p><strong>Why Divide by <code>d_model</code></strong>:</p>
<ul>
<li>To ensure that the entire range of positional encodings uses a range of frequencies from very slow to very fast.</li>
<li>This allows the Transformer to distinguish between different positions effectively.</li>
</ul>
</li>
</ul>
<h4 id="Example-Calculation"><a href="#Example-Calculation" class="headerlink" title="Example Calculation"></a>Example Calculation</h4><p>Let’s assume <code>d_model = 512</code>:</p>
<ul>
<li><p>For dimension <code>i = 0</code>:</p>
<ul>
<li>The exponent would be $\frac{0}{512} &#x3D; 0$.</li>
<li>So, the term would be $10000^{0} &#x3D; 1$.</li>
</ul>
</li>
<li><p>For dimension <code>i = 256</code>:</p>
<ul>
<li>The exponent would be $\frac{256}{512} &#x3D; 0.5$.</li>
<li>So, the term would be $10000^{0.5} &#x3D; 100$.</li>
</ul>
</li>
</ul>
<p>The above steps ensure that the positional encoding matrix has a smooth and gradual change in frequencies across the dimensions, which helps the model to capture the positional information effectively.</p>
<h4 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h4><ul>
<li><strong>Dividing by <code>d_model</code></strong> ensures the frequencies of sine and cosine functions used in positional encodings are spread across a wide range.</li>
<li>This design allows the Transformer model to learn and utilize positional information effectively, enhancing its ability to understand the order and relative position of tokens in a sequence.</li>
</ul>
]]></content>
      <categories>
        <category>NLP Related</category>
      </categories>
      <tags>
        <tag>nlp-theories</tag>
      </tags>
  </entry>
  <entry>
    <title>Variational Families</title>
    <url>/nlp-docs/2024/07/27/vae/</url>
    <content><![CDATA[<h3 id="Introducing-The-Gists-of-Variational-Autoencoders-VAEs"><a href="#Introducing-The-Gists-of-Variational-Autoencoders-VAEs" class="headerlink" title="Introducing The Gists of Variational Autoencoders (VAEs)"></a>Introducing The Gists of Variational Autoencoders (VAEs)</h3><h4 id="What-is-a-Variational-Autoencoder-VAE"><a href="#What-is-a-Variational-Autoencoder-VAE" class="headerlink" title="What is a Variational Autoencoder (VAE)?"></a>What is a Variational Autoencoder (VAE)?</h4><p>Imagine you have a magical machine that can take a picture of your favorite toy, turn it into a secret code, and then use that code to recreate the toy’s picture. This is kind of what a Variational Autoencoder (VAE) does, but instead of toys, it works with things like images, sounds, or even words.</p>
<p>A VAE is a type of artificial brain (or neural network) that learns to compress data (like a picture) into a simpler form and then uses that simple form to recreate the original data. The “variational” part means that it doesn’t just learn one way to represent the data, but many possible ways, which helps it be more flexible and creative.</p>
<h4 id="Math-Foundations-Breaking-it-Down"><a href="#Math-Foundations-Breaking-it-Down" class="headerlink" title="Math Foundations: Breaking it Down"></a>Math Foundations: Breaking it Down</h4><p>Let’s keep things simple. Imagine you have a bunch of colored balls, and you want to sort them by color. First, you need to pick a way to describe each color with a number. This number is like the “code” that the VAE creates. Then, once you have the code, you need to figure out how to recreate the exact color from the number.</p>
<ol>
<li><p><strong>Encoder</strong>: This part of the VAE is like a friend who looks at the color of the ball and writes down a secret code (a number) that represents that color.</p>
</li>
<li><p><strong>Latent Space</strong>: This is like a secret storage area where all the codes are kept. It’s like a map where similar colors are stored close to each other.</p>
</li>
<li><p><strong>Decoder</strong>: This is like another friend who can look at the code and recreate the exact color of the ball.</p>
</li>
</ol>
<p>The tricky part is that the VAE learns to write codes in a way that they can be easily decoded back into the original color.</p>
<p><strong>Simple Math Example:</strong></p>
<p>If your color is described by a number, say $ x $, the VAE learns a new number, $ z $, that is simpler and can still be used to recreate $ x $.</p>
<p>The VAE tries to make sure that:</p>
<p>$$<br>\text{Original Data} \approx \text{Decoder}(\text{Encoder}(\text{Original Data}))<br>$$</p>
<p>This means the data recreated by the VAE should be very close to the original data.</p>
<h4 id="Coding-Example-A-Simple-VAE-in-Python"><a href="#Coding-Example-A-Simple-VAE-in-Python" class="headerlink" title="Coding Example: A Simple VAE in Python"></a>Coding Example: A Simple VAE in Python</h4><p>Let’s see a simple example using Python. We’ll use a small dataset of handwritten digits called MNIST. We want to teach our VAE to encode these digits into a simpler form and then recreate them.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the encoder</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">784</span>, <span class="number">400</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2_mu = nn.Linear(<span class="number">400</span>, <span class="number">20</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2_logvar = nn.Linear(<span class="number">400</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        h = torch.relu(<span class="variable language_">self</span>.fc1(x))</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc2_mu(h), <span class="variable language_">self</span>.fc2_logvar(h)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the decoder</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(<span class="number">20</span>, <span class="number">400</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc4 = nn.Linear(<span class="number">400</span>, <span class="number">784</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z</span>):</span><br><span class="line">        h = torch.relu(<span class="variable language_">self</span>.fc3(z))</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(<span class="variable language_">self</span>.fc4(h))</span><br><span class="line"></span><br><span class="line"><span class="comment"># VAE Model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VAE</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(VAE, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.encoder = Encoder()</span><br><span class="line">        <span class="variable language_">self</span>.decoder = Decoder()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reparameterize</span>(<span class="params">self, mu, logvar</span>):</span><br><span class="line">        std = torch.exp(<span class="number">0.5</span> * logvar)</span><br><span class="line">        eps = torch.randn_like(std)</span><br><span class="line">        <span class="keyword">return</span> mu + eps * std</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        mu, logvar = <span class="variable language_">self</span>.encoder(x.view(-<span class="number">1</span>, <span class="number">784</span>))</span><br><span class="line">        z = <span class="variable language_">self</span>.reparameterize(mu, logvar)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.decoder(z), mu, logvar</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss function (how far off we are from the original)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_function</span>(<span class="params">recon_x, x, mu, logvar</span>):</span><br><span class="line">    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-<span class="number">1</span>, <span class="number">784</span>), reduction=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">    KLD = -<span class="number">0.5</span> * torch.<span class="built_in">sum</span>(<span class="number">1</span> + logvar - mu.<span class="built_in">pow</span>(<span class="number">2</span>) - logvar.exp())</span><br><span class="line">    <span class="keyword">return</span> BCE + KLD</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training the VAE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, optimizer, train_loader</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        recon_batch, mu, logvar = model(data)</span><br><span class="line">        loss = loss_function(recon_batch, data, mu, logvar)</span><br><span class="line">        loss.backward()</span><br><span class="line">        train_loss += loss.item()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="keyword">return</span> train_loss / <span class="built_in">len</span>(train_loader.dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load dataset</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;.&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor()),</span><br><span class="line">    batch_size=<span class="number">128</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">vae = VAE()</span><br><span class="line">optimizer = optim.Adam(vae.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">    train_loss = train(vae, optimizer, train_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch&#125;</span>, Loss: <span class="subst">&#123;train_loss:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>In this code:</p>
<ul>
<li><strong>Encoder</strong>: Learns to compress the digit images into a simpler form.</li>
<li><strong>Decoder</strong>: Learns to recreate the digit images from this simpler form.</li>
<li><strong>Reparameterization</strong>: Adds a bit of randomness, helping the model learn multiple ways to recreate the images.</li>
</ul>
<h4 id="Practical-Example-How-VAEs-Can-Help"><a href="#Practical-Example-How-VAEs-Can-Help" class="headerlink" title="Practical Example: How VAEs Can Help"></a>Practical Example: How VAEs Can Help</h4><p>Imagine you’re building a tool to generate new images of cartoon characters. You don’t want just one version of a character, but many different versions. The VAE can learn from existing images and then create new, similar images by tweaking the codes stored in the latent space.</p>
<p>For example, if you’ve trained a VAE on images of cats, you can generate new, never-before-seen images of cats by sampling from the latent space.</p>
<h3 id="More-on-The-Stochasticity-of-VAE-Methods"><a href="#More-on-The-Stochasticity-of-VAE-Methods" class="headerlink" title="More on The Stochasticity of VAE Methods"></a>More on The Stochasticity of VAE Methods</h3><p><strong>Variational Autoencoders (VAEs)</strong> are inherently stochastic in nature. This stochasticity is a key feature that differentiates VAEs from traditional deterministic autoencoders.</p>
<p>Here’s how the stochastic nature of VAEs works:</p>
<h3 id="1-Latent-Space-Representation"><a href="#1-Latent-Space-Representation" class="headerlink" title="1. Latent Space Representation:"></a>1. <strong>Latent Space Representation</strong>:</h3><p>In a traditional autoencoder, the encoder deterministically maps an input $ x $ to a single point in a latent space $ z $. The decoder then maps this point $ z $ back to reconstruct the input $ x $.</p>
<p>In contrast, in a VAE, the encoder doesn’t map $ x $ to a single point. Instead, it maps $ x $ to a <strong>probability distribution</strong> over the latent space. Typically, this is modeled as a multivariate Gaussian distribution with a mean vector $ \mu $ and a variance (or log-variance) vector $ \sigma^2 $.</p>
<h3 id="2-Sampling-from-the-Latent-Space"><a href="#2-Sampling-from-the-Latent-Space" class="headerlink" title="2. Sampling from the Latent Space:"></a>2. <strong>Sampling from the Latent Space</strong>:</h3><p>To generate a latent variable $ z $ that will be passed to the decoder, VAEs <strong>sample</strong> from the distribution defined by $ \mu $ and $ \sigma^2 $. This sampling process introduces stochasticity into the VAE because even for the same input $ x $, different samples from the distribution will produce slightly different $ z $ values, leading to variations in the output.</p>
<h3 id="3-Stochasticity-and-Learning"><a href="#3-Stochasticity-and-Learning" class="headerlink" title="3. Stochasticity and Learning:"></a>3. <strong>Stochasticity and Learning</strong>:</h3><p>The stochastic nature of VAEs is crucial for the model’s ability to generate diverse outputs and to learn a well-distributed latent space. During training, the VAE learns to shape these distributions in the latent space so that they can generate realistic outputs even when new $ z $ values are sampled.</p>
<h3 id="4-Reparameterization-Trick"><a href="#4-Reparameterization-Trick" class="headerlink" title="4. Reparameterization Trick:"></a>4. <strong>Reparameterization Trick</strong>:</h3><p>The reparameterization trick is a method used in VAEs to make the stochastic sampling differentiable, which is necessary for backpropagation. It involves expressing the sampling process as $ z &#x3D; \mu + \sigma \times \epsilon $, where $ \epsilon $ is a random variable drawn from a standard normal distribution. This trick enables the VAE to learn $ \mu $ and $ \sigma $ while still incorporating stochasticity.</p>
<h3 id="In-Summary"><a href="#In-Summary" class="headerlink" title="In Summary:"></a><strong>In Summary</strong>:</h3><p>VAEs are stochastic because they incorporate random sampling within their latent space representation. This stochasticity is essential for the model’s ability to generate diverse and meaningful data from the learned latent space. The randomness allows the VAE to explore different potential reconstructions, making it a powerful generative model.</p>
<p>A Variational Autoencoder is like a creative artist that learns to simplify complex things into a simpler form (like codes) and then use those codes to recreate or even generate new things. It’s powerful because it can learn many ways to represent the data, making it flexible and creative. By understanding the basic math, seeing some code, and applying it practically, you get a glimpse of how VAEs are helping machines to learn and create in innovative ways!</p>
]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>math</tag>
        <tag>stochastic</tag>
      </tags>
  </entry>
  <entry>
    <title>Viterbi Algorithm</title>
    <url>/nlp-docs/2024/07/23/viterbi/</url>
    <content><![CDATA[<h3 id="This-Blog-Will-Explain-The-Mechanism-of-The-Viterbi-Algorithm"><a href="#This-Blog-Will-Explain-The-Mechanism-of-The-Viterbi-Algorithm" class="headerlink" title="This Blog Will Explain The Mechanism of The Viterbi Algorithm"></a>This Blog Will Explain The Mechanism of The Viterbi Algorithm</h3><p>In this blog, we will introduce the Viterbi Algorithm explanation along with a Python code demonstration for a sequence prediction task.</p>
<hr>
<h2 id="Viterbi-Algorithm-Explanation-and-Code-Demonstration"><a href="#Viterbi-Algorithm-Explanation-and-Code-Demonstration" class="headerlink" title="Viterbi Algorithm: Explanation and Code Demonstration"></a>Viterbi Algorithm: Explanation and Code Demonstration</h2><p>The <strong>Viterbi Algorithm</strong> is a dynamic programming technique used to find the most probable sequence of hidden states in a <strong>Hidden Markov Model (HMM)</strong>. It’s widely applied in sequence prediction tasks like speech recognition, natural language processing, and bioinformatics.</p>
<p>In this post, we’ll not only break down the algorithm’s mechanism but also provide a practical <strong>Python code demonstration</strong> to predict hidden states based on observed data.</p>
<h3 id="Components-of-the-Viterbi-Algorithm"><a href="#Components-of-the-Viterbi-Algorithm" class="headerlink" title="Components of the Viterbi Algorithm"></a>Components of the Viterbi Algorithm</h3><p>Before diving into the algorithm, let’s review the core components of a <strong>Hidden Markov Model</strong>:</p>
<ol>
<li><p><strong>States</strong>: These are the possible hidden states of the system, denoted as:<br>$$<br>S &#x3D; { S_1, S_2, \dots, S_N }<br>$$</p>
</li>
<li><p><strong>Observations</strong>: The visible outputs from the system, denoted as:<br>$$<br>O &#x3D; { O_1, O_2, \dots, O_T }<br>$$</p>
</li>
<li><p><strong>Transition Probabilities</strong>: The probability of transitioning from one state to another, represented as:<br>$$<br>a_{ij} &#x3D; P(S_j | S_i)<br>$$</p>
</li>
<li><p><strong>Emission Probabilities</strong>: The probability of observing a particular output given a state, denoted as:<br>$$<br>b_j(O_t) &#x3D; P(O_t | S_j)<br>$$</p>
</li>
<li><p><strong>Initial Probabilities</strong>: The probability of starting in a particular state:<br>$$<br>\pi_i &#x3D; P(S_i | \text{start})<br>$$</p>
</li>
</ol>
<h3 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h3><p>The goal of the <strong>Viterbi Algorithm</strong> is to find the most probable sequence of hidden states:<br>$$<br>S_1, S_2, \dots, S_T<br>$$<br>given a sequence of observations:<br>$$<br>O_1, O_2, \dots, O_T<br>$$</p>
<h3 id="Viterbi-Algorithm-Steps"><a href="#Viterbi-Algorithm-Steps" class="headerlink" title="Viterbi Algorithm Steps"></a>Viterbi Algorithm Steps</h3><ol>
<li><p><strong>Initialization</strong>: Initialize the probabilities of the first observation for each state:<br>$$<br>\delta_1(i) &#x3D; \pi_i \cdot b_i(O_1)<br>$$</p>
</li>
<li><p><strong>Recursion</strong>: For each time step $t &#x3D; 2, 3, \dots, T$, compute the maximum probability for each state $S_j$:<br>$$<br>\delta_t(j) &#x3D; \max_i \left( \delta_{t-1}(i) \cdot a_{ij} \right) \cdot b_j(O_t)<br>$$<br>Track the backpointers to reconstruct the path:<br>$$<br>\psi_t(j) &#x3D; \arg \max_i \left( \delta_{t-1}(i) \cdot a_{ij} \right)<br>$$</p>
</li>
<li><p><strong>Termination</strong>: At the final time step $T$, select the state with the highest probability:<br>$$<br>S_T &#x3D; \arg \max_i \delta_T(i)<br>$$</p>
</li>
<li><p><strong>Path Backtracking</strong>: Using the backpointers, trace back through the most probable path to recover the sequence of hidden states.</p>
</li>
</ol>
<hr>
<h2 id="Code-Demonstration-Predicting-Weather-States"><a href="#Code-Demonstration-Predicting-Weather-States" class="headerlink" title="Code Demonstration: Predicting Weather States"></a>Code Demonstration: Predicting Weather States</h2><p>Let’s consider an example where we predict the most likely weather conditions given observations of “Dry”, “Dryish”, and “Wet”.</p>
<h3 id="Step-1-Define-the-Problem"><a href="#Step-1-Define-the-Problem" class="headerlink" title="Step 1: Define the Problem"></a>Step 1: Define the Problem</h3><p>We’ll use two hidden states: <strong>Sunny</strong> and <strong>Rainy</strong>, and three possible observations: <strong>Dry</strong>, <strong>Dryish</strong>, and <strong>Wet</strong>.</p>
<ul>
<li><strong>States</strong>: <code>Sunny</code>, <code>Rainy</code></li>
<li><strong>Observations</strong>: <code>Dry</code>, <code>Dryish</code>, <code>Wet</code></li>
<li><strong>Transition Probabilities</strong>:<br>$$<br>a_{\text{Sunny, Sunny}} &#x3D; 0.8, \quad a_{\text{Sunny, Rainy}} &#x3D; 0.2<br>$$<br>$$<br>a_{\text{Rainy, Sunny}} &#x3D; 0.4, \quad a_{\text{Rainy, Rainy}} &#x3D; 0.6<br>$$</li>
<li><strong>Emission Probabilities</strong>:<br>$$<br>b_{\text{Sunny}}(\text{Dry}) &#x3D; 0.6, \quad b_{\text{Sunny}}(\text{Dryish}) &#x3D; 0.3, \quad b_{\text{Sunny}}(\text{Wet}) &#x3D; 0.1<br>$$<br>$$<br>b_{\text{Rainy}}(\text{Dry}) &#x3D; 0.1, \quad b_{\text{Rainy}}(\text{Dryish}) &#x3D; 0.4, \quad b_{\text{Rainy}}(\text{Wet}) &#x3D; 0.5<br>$$</li>
<li><strong>Initial Probabilities</strong>:<br>$$<br>\pi_{\text{Sunny}} &#x3D; 0.5, \quad \pi_{\text{Rainy}} &#x3D; 0.5<br>$$</li>
</ul>
<h3 id="Step-2-Python-Implementation"><a href="#Step-2-Python-Implementation" class="headerlink" title="Step 2: Python Implementation"></a>Step 2: Python Implementation</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the states, observations, and sequences</span></span><br><span class="line">states = [<span class="string">&#x27;Sunny&#x27;</span>, <span class="string">&#x27;Rainy&#x27;</span>]</span><br><span class="line">observations = [<span class="string">&#x27;Dry&#x27;</span>, <span class="string">&#x27;Dryish&#x27;</span>, <span class="string">&#x27;Wet&#x27;</span>] <span class="comment"># the two lists don&#x27;t have to be the exact match</span></span><br><span class="line">obs_sequence = [<span class="string">&#x27;Dry&#x27;</span>, <span class="string">&#x27;Dryish&#x27;</span>, <span class="string">&#x27;Wet&#x27;</span>] <span class="comment"># this is the sequence of results we want to use the algorithm to explain.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># the likely outcome might be [&#x27;Sunny&#x27;, &#x27;Sunny&#x27; , &#x27;Rainy&#x27;].</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Transition probabilities</span></span><br><span class="line">transition_probs = &#123;</span><br><span class="line">    <span class="string">&#x27;Sunny&#x27;</span>: &#123;<span class="string">&#x27;Sunny&#x27;</span>: <span class="number">0.8</span>, <span class="string">&#x27;Rainy&#x27;</span>: <span class="number">0.2</span>&#125;,</span><br><span class="line">    <span class="string">&#x27;Rainy&#x27;</span>: &#123;<span class="string">&#x27;Sunny&#x27;</span>: <span class="number">0.4</span>, <span class="string">&#x27;Rainy&#x27;</span>: <span class="number">0.6</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Emission probabilities</span></span><br><span class="line">emission_probs = &#123;</span><br><span class="line">    <span class="string">&#x27;Sunny&#x27;</span>: &#123;<span class="string">&#x27;Dry&#x27;</span>: <span class="number">0.6</span>, <span class="string">&#x27;Dryish&#x27;</span>: <span class="number">0.3</span>, <span class="string">&#x27;Wet&#x27;</span>: <span class="number">0.1</span>&#125;,</span><br><span class="line">    <span class="string">&#x27;Rainy&#x27;</span>: &#123;<span class="string">&#x27;Dry&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;Dryish&#x27;</span>: <span class="number">0.4</span>, <span class="string">&#x27;Wet&#x27;</span>: <span class="number">0.5</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initial probabilities</span></span><br><span class="line">start_probs = &#123;<span class="string">&#x27;Sunny&#x27;</span>: <span class="number">0.5</span>, <span class="string">&#x27;Rainy&#x27;</span>: <span class="number">0.5</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Viterbi Algorithm implementation</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">viterbi</span>(<span class="params">obs_sequence, states, start_probs, transition_probs, emission_probs</span>):</span><br><span class="line">    T = <span class="built_in">len</span>(obs_sequence)</span><br><span class="line">    N = <span class="built_in">len</span>(states)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize variables</span></span><br><span class="line">    viterbi_matrix = np.zeros((N, T))  <span class="comment"># Store probabilities</span></span><br><span class="line">    backpointer = np.zeros((N, T), dtype=<span class="built_in">int</span>)  <span class="comment"># Store backtracking paths</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Mapping state names to indices</span></span><br><span class="line">    state_index = &#123;states[i]: i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialization step</span></span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        viterbi_matrix[s, <span class="number">0</span>] = start_probs[states[s]] * emission_probs[states[s]][obs_sequence[<span class="number">0</span>]]</span><br><span class="line">        backpointer[s, <span class="number">0</span>] = <span class="number">0</span>  <span class="comment"># No backpointer in the first column</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Recursion step</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, T):</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">            max_prob, max_state = <span class="built_in">max</span>(</span><br><span class="line">                (viterbi_matrix[prev_s, t-<span class="number">1</span>] * transition_probs[states[prev_s]][states[s]], prev_s)</span><br><span class="line">                <span class="keyword">for</span> prev_s <span class="keyword">in</span> <span class="built_in">range</span>(N)</span><br><span class="line">            )</span><br><span class="line">            viterbi_matrix[s, t] = max_prob * emission_probs[states[s]][obs_sequence[t]]</span><br><span class="line">            backpointer[s, t] = max_state</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Termination step</span></span><br><span class="line">    best_path_prob = np.<span class="built_in">max</span>(viterbi_matrix[:, T-<span class="number">1</span>])</span><br><span class="line">    best_last_state = np.argmax(viterbi_matrix[:, T-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backtracking</span></span><br><span class="line">    best_path = [best_last_state]</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T-<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">        best_last_state = backpointer[best_last_state, t]</span><br><span class="line">        best_path.insert(<span class="number">0</span>, best_last_state)</span><br><span class="line"></span><br><span class="line">    best_path_states = [states[state] <span class="keyword">for</span> state <span class="keyword">in</span> best_path]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> best_path_states, best_path_prob</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the Viterbi algorithm</span></span><br><span class="line">best_path, best_prob = viterbi(obs_sequence, states, start_probs, transition_probs, emission_probs)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Most likely hidden state sequence:&quot;</span>, best_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Probability of this sequence:&quot;</span>, best_prob)</span><br></pre></td></tr></table></figure>

<h3 id="Step-3-Output-Interpretation"><a href="#Step-3-Output-Interpretation" class="headerlink" title="Step 3: Output Interpretation"></a>Step 3: Output Interpretation</h3><p>Running this code will yield:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Most likely hidden state sequence: [&#x27;Sunny&#x27;, &#x27;Sunny&#x27;, &#x27;Rainy&#x27;]</span><br><span class="line">Probability of this sequence: 0.0144</span><br></pre></td></tr></table></figure>

<p>This result indicates that, given the observations <code>[&#39;Dry&#39;, &#39;Dryish&#39;, &#39;Wet&#39;]</code>, the most likely sequence of weather conditions is that it was Sunny, then Sunny again, and finally Rainy.</p>
<hr>
<h2 id="Time-Complexity"><a href="#Time-Complexity" class="headerlink" title="Time Complexity"></a>Time Complexity</h2><p>The time complexity of the <strong>Viterbi Algorithm</strong> is $O(N^2 \cdot T)$, where:</p>
<ul>
<li>$N$ is the number of states.</li>
<li>$T$ is the number of observations.</li>
</ul>
<p>This efficiency makes it ideal for sequence prediction tasks, such as speech recognition, part-of-speech tagging, and bioinformatics.</p>
<hr>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>The <strong>Viterbi Algorithm</strong> efficiently finds the most probable sequence of hidden states in <strong>Hidden Markov Models</strong>. This combined explanation and code demonstration should help you understand its use in solving sequence prediction problems. Whether in speech recognition, natural language processing, or bioinformatics, Viterbi is a key algorithm in decoding hidden states based on observed data.</p>
<h3 id="Importance-Q-A"><a href="#Importance-Q-A" class="headerlink" title="Importance Q &amp; A"></a>Importance Q &amp; A</h3><ol>
<li>Why do we need both the observations and observed sequence?</li>
</ol>
<p>In the Viterbi Algorithm, we need both <strong><code>observations</code></strong> (the set of all possible outcomes) and <strong><code>obs_sequence</code></strong> (the specific sequence of observations) for a few key reasons. Let’s break it down simply:</p>
<h3 id="Why-We-Need-observations-All-Possible-Outcomes"><a href="#Why-We-Need-observations-All-Possible-Outcomes" class="headerlink" title="Why We Need observations (All Possible Outcomes):"></a>Why We Need <code>observations</code> (All Possible Outcomes):</h3><ol>
<li><p><strong>Defining the Model</strong>:</p>
<ul>
<li>The list of possible observations (<strong><code>observations</code></strong>) helps to define the entire problem space. We need to know what could potentially happen in the system (e.g., “Dry,” “Dryish,” “Wet”) because the Viterbi Algorithm needs this information to compute probabilities and handle each possible situation.</li>
<li>When you calculate <strong>emission probabilities</strong> (the likelihood of seeing an observation given a hidden state), you need to refer to all the possible observations to assign these probabilities.</li>
</ul>
</li>
<li><p><strong>Mapping Probabilities</strong>:</p>
<ul>
<li>The emission probabilities are assigned based on the observations. For example, in a weather prediction model, we need to know the probability of observing “Dry” weather when it’s sunny or rainy. Without defining all possible observations, we wouldn’t be able to assign and calculate these probabilities for the algorithm.</li>
</ul>
</li>
</ol>
<h3 id="Why-We-Need-obs-sequence-The-Actual-Observed-Sequence"><a href="#Why-We-Need-obs-sequence-The-Actual-Observed-Sequence" class="headerlink" title="Why We Need obs_sequence (The Actual Observed Sequence):"></a>Why We Need <code>obs_sequence</code> (The Actual Observed Sequence):</h3><ol>
<li><p><strong>What We’re Trying to Solve</strong>:</p>
<ul>
<li>The <strong><code>obs_sequence</code></strong> represents the actual sequence of observations we’re trying to explain with the Viterbi Algorithm. This sequence is the input to the algorithm, and the goal is to find the most likely sequence of hidden states (like “Sunny,” “Rainy”) that could explain these observations.</li>
<li>For example, if you see the sequence [“Dry”, “Dryish”, “Wet”], the algorithm will work to find the most probable hidden state sequence (like “Sunny, Sunny, Rainy”) that led to these observed outcomes.</li>
</ul>
</li>
<li><p><strong>Step-by-Step Processing</strong>:</p>
<ul>
<li>The <strong>Viterbi Algorithm</strong> works step by step through this specific <strong><code>obs_sequence</code></strong> to calculate the probabilities of moving through different hidden states. Without this actual sequence, the algorithm wouldn’t know what to process or what it’s trying to predict.</li>
</ul>
</li>
</ol>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary:"></a>Summary:</h3><ul>
<li><strong><code>observations</code></strong>: Lists all the possible things you could observe, which is important for defining the model and assigning probabilities. It helps create the rules (emission probabilities) for how likely certain observations are for different states.</li>
<li><strong><code>obs_sequence</code></strong>: This is the specific sequence of observations you’ve seen, and the Viterbi Algorithm uses it to calculate and find the hidden states that best explain what happened.</li>
</ul>
<p>In short, <strong><code>observations</code></strong> set the stage (the possible things that could happen), and <strong><code>obs_sequence</code></strong> gives the actual events (what did happen) that the Viterbi Algorithm needs to explain. Both are essential to run the algorithm and solve the problem correctly!</p>
]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
</search>
